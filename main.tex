%release 2025.0
% !TEX root = main.tex
\documentclass[letterpaper]{article} % DO NOT CHANGE THIS
\usepackage{aaai25}  % DO NOT CHANGE THIS
\usepackage{times}  % DO NOT CHANGE THIS
\usepackage{helvet}  % DO NOT CHANGE THIS
\usepackage{courier}  % DO NOT CHANGE THIS
\usepackage[hyphens]{url}  % DO NOT CHANGE THIS
\usepackage{graphicx} % DO NOT CHANGE THIS
\urlstyle{rm} % DO NOT CHANGE THIS
\def\UrlFont{\rm}  % DO NOT CHANGE THIS
\usepackage{natbib}  % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT
\usepackage{caption} % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT
\frenchspacing  % DO NOT CHANGE THIS
\setlength{\pdfpagewidth}{8.5in}  % DO NOT CHANGE THIS
\setlength{\pdfpageheight}{11in}  % DO NOT CHANGE THIS
%
% These are recommended to typeset algorithms but not required. See the subsubsection on algorithms. Remove them if you don't have algorithms in your paper.
\usepackage{algorithm}
\usepackage{algorithmic}

%
% These are are recommended to typeset listings but not required. See the subsubsection on listing. Remove this block if you don't have listings in your paper.
\usepackage{newfloat}
\usepackage{listings}
\DeclareCaptionStyle{ruled}{labelfont=normalfont,labelsep=colon,strut=off} % DO NOT CHANGE THIS
\lstset{%
	basicstyle={\footnotesize\ttfamily},% footnotesize acceptable for monospace
	numbers=left,numberstyle=\footnotesize,xleftmargin=2em,% show line numbers, remove this entire line if you don't want the numbers.
	aboveskip=0pt,belowskip=0pt,%
	showstringspaces=false,tabsize=2,breaklines=true}
\floatstyle{ruled}
\newfloat{listing}{tb}{lst}{}
\floatname{listing}{Listing}
%
% Keep the \pdfinfo as shown here. There's no need
% for you to add the /Title and /Author tags.
\pdfinfo{
/TemplateVersion (2025.1)
}

% DISALLOWED PACKAGES
% \usepackage{authblk} -- This package is specifically forbidden
% \usepackage{balance} -- This package is specifically forbidden
% \usepackage{color (if used in text)
% \usepackage{CJK} -- This package is specifically forbidden
% \usepackage{float} -- This package is specifically forbidden
% \usepackage{flushend} -- This package is specifically forbidden
% \usepackage{fontenc} -- This package is specifically forbidden
% \usepackage{fullpage} -- This package is specifically forbidden
% \usepackage{geometry} -- This package is specifically forbidden
% \usepackage{grffile} -- This package is specifically forbidden
% \usepackage{hyperref} -- This package is specifically forbidden
% \usepackage{navigator} -- This package is specifically forbidden
% (or any other package that embeds links such as navigator or hyperref)
% \indentfirst} -- This package is specifically forbidden
% \layout} -- This package is specifically forbidden
% \multicol} -- This package is specifically forbidden
% \nameref} -- This package is specifically forbidden
% \usepackage{savetrees} -- This package is specifically forbidden
% \usepackage{setspace} -- This package is specifically forbidden
% \usepackage{stfloats} -- This package is specifically forbidden
% \usepackage{tabu} -- This package is specifically forbidden
% \usepackage{titlesec} -- This package is specifically forbidden
% \usepackage{tocbibind} -- This package is specifically forbidden
% \usepackage{ulem} -- This package is specifically forbidden
% \usepackage{wrapfig} -- This package is specifically forbidden
% DISALLOWED COMMANDS
% \nocopyright -- Your paper will not be published if you use this command
% \addtolength -- This command may not be used
% \balance -- This command may not be used
% \baselinestretch -- Your paper will not be published if you use this command
% \clearpage -- No page breaks of any kind may be used for the final version of your paper
% \columnsep -- This command may not be used
% \newpage -- No page breaks of any kind may be used for the final version of your paper
% \pagebreak -- No page breaks of any kind may be used for the final version of your paperr
% \pagestyle -- This command may not be used
% \tiny -- This is not an acceptable font size.
% \vspace{- -- No negative value may be used in proximity of a caption, figure, table, section, subsection, subsubsection, or reference
% \vskip{- -- No negative value may be used to alter spacing above or below a caption, figure, table, section, subsection, subsubsection, or reference

\setcounter{secnumdepth}{2} %May be changed to 1 or 2 if section numbers are desired.

% The file aaai25.sty is the style file for AAAI Press
% proceedings, working notes, and technical reports.
%

% Title

% Your title must be in mixed case, not sentence case.
% That means all verbs (including short verbs like be, is, using,and go),
% nouns, adverbs, adjectives should be capitalized, including both words in hyphenated terms, while
% articles, conjunctions, and prepositions are lower case unless they
% directly follow a colon or long dash
\title{Planning Approaches for Game Artificial Intelligence: A Survey}
\author{
    %Authors
    % All authors must be in the same font size and format.
    % Written by AAAI Press Staff\textsuperscript{\rm 1}\thanks{With help from the AAAI Publications Committee.}\\
    % AAAI Style Contributions by Samanth Nanda Kumar,\\
    % J. Scott Penberthy,
    % George Ferguson,
    % Hans Guesgen,
    % Francisco Cruz\equalcontrib,
    % Marc Pujol-Gonzalez\equalcontrib
    Samanth Nanda Kumar \\
    UniversitÃ¤t Stuttgart \\
    \texttt{st193225@stud.uni-stuttgart.de}
}
% \affiliations{
%     %Afiliations
%     \textsuperscript{\rm 1}Association for the Advancement of Artificial Intelligence\\
%     % If you have multiple authors and multiple affiliations
%     % use superscripts in text and roman font to identify them.
%     % For example,

%     % Sunil Issar\textsuperscript{\rm 2}, 
%     % J. Scott Penberthy\textsuperscript{\rm 3}, 
%     % George Ferguson\textsuperscript{\rm 4},
%     % Hans Guesgen\textsuperscript{\rm 5}
%     % Note that the comma should be placed after the superscript

%     1101 Pennsylvania Ave, NW Suite 300\\
%     Washington, DC 20004 USA\\
%     % email address must be in roman text type, not monospace or sans serif
%     proceedings-questions@aaai.org
% %
% % See more examples next
% }

%Example, Single Author, ->> remove \iffalse,\fi and place them surrounding AAAI title to use it
\iffalse
\title{My Publication Title --- Single Author}
\author {
    Author Name
}
\affiliations{
    Affiliation\\
    Affiliation Line 2\\
    name@example.com
}
\fi

\iffalse
%Example, Multiple Authors, ->> remove \iffalse,\fi and place them surrounding AAAI title to use it
\title{My Publication Title --- Multiple Authors}
\author {
    % Authors
    First Author Name\textsuperscript{\rm 1,\rm 2},
    Second Author Name\textsuperscript{\rm 2},
    Third Author Name\textsuperscript{\rm 1}
}
\affiliations {
    % Affiliations
    \textsuperscript{\rm 1}Affiliation 1\\
    \textsuperscript{\rm 2}Affiliation 2\\
    firstAuthor@affiliation1.com, secondAuthor@affilation2.com, thirdAuthor@affiliation1.com
}
\fi


% REMOVE THIS: bibentry
% This is only needed to show inline citations in the guidelines document. You should not need it and can safely delete it.
\usepackage{bibentry}
% END REMOVE bibentry

\begin{document}

\maketitle

\begin{abstract}
    Artificial intelligence planning has long been explored as a principled approach for generating goal-directed behavior in games. Unlike purely reactive control architectures, planning-based methods explicitly reason about actions, goals, and their consequences, enabling more flexible and adaptive agent behavior. However, the application of planning in games introduces unique challenges, including real-time constraints, highly dynamic environments, and the need for designer control. This paper presents a literature survey of planning approaches applied to games, focusing on hierarchical symbolic planning, goal-oriented action planning, and search-based planning with state abstraction. We analyze representative methods from both academic research and industry practice, compare their strengths and limitations, and discuss open challenges that motivate future research in game AI planning.
\end{abstract}

% Uncomment the following to link to your code, datasets, an extended version or similar.
%
% \begin{links}
%     \link{Code}{https://aaai.org/example/code}
%     \link{Datasets}{https://aaai.org/example/datasets}
%     \link{Extended version}{https://aaai.org/example/extended-version}
% \end{links}

\section{Introduction}

Digital games constitute a challenging and diverse domain for artificial intelligence research. Contemporary games combine large state and action spaces with real-time decision making, stochastic outcomes, and environments that evolve continuously in response to both system dynamics and human player behavior. For these reasons, games have long served not only as experimental testbeds for AI research, but also as application domains in which theoretical methods must be adapted to strict performance, robustness, and design constraints. Within this context, AI planning has emerged as a principled approach for generating goal-directed behavior, providing an alternative to purely reactive or heavily scripted control architectures \cite{hoang2005hierarchical}.

Traditional game AI techniques, such as finite state machines and behavior trees, remain widely used due to their simplicity, predictability, and low computational overhead. However, as game worlds expand in scope and agent responsibilities become more complex, these approaches often struggle to scale. Authoring effort increases substantially, behavior logic becomes difficult to maintain, and agents exhibit limited flexibility when confronted with situations not explicitly anticipated during design. Planning-based approaches seek to address these limitations by explicitly modeling goals, actions, and state transitions, thereby enabling agents to reason about future consequences and revise their behavior dynamically during execution \cite{kelly2007planning}. As a result, planning techniques have been explored across a broad range of game genres, including fast-paced action games as well as large-scale strategy and simulation environments.

Despite their conceptual appeal, planning techniques face significant challenges when applied to games. Classical planning formulations typically assume static environments, offline computation, and complete knowledge of the world state. In contrast, game environments are subject to frequent and unpredictable changes, tight real-time constraints, and strong requirements for designer oversight to ensure believable and controllable agent behavior. These discrepancies have motivated the development of planning approaches that are explicitly tailored to the demands of games, rather than direct applications of classical planners \cite{neufeld2017htn}.

One prominent line of work focuses on hierarchical planning, particularly Hierarchical Task Network (HTN) methods, which decompose complex behaviors into structured subtasks while preserving designer-authored strategic knowledge. HTN-based approaches have proven effective in games that require long-term planning and coordination, while still allowing adaptation during execution. In parallel, Goal-Oriented Action Planning (GOAP) has been adopted in commercial game development as a more lightweight and flexible alternative to large finite state machines. By decoupling goals from actions and relying on frequent replanning, GOAP enables agents to respond adaptively to changing world states, as demonstrated in commercial titles \cite{orkin2006three}.

More recently, search-based planning approaches inspired by Monte Carlo Tree Search (MCTS) have been investigated as a means of handling large decision spaces under uncertainty. These methods typically rely on abstraction techniques to manage computational complexity, trading exact reasoning for scalable approximation. Such approaches are particularly relevant in strategy and simulation games, where exhaustive planning is infeasible and adaptability is essential \cite{xu2022elastic}.

The remainder of this paper is organized as follows. Section~2 provides background on AI planning and discusses the challenges that arise when applying classical planning techniques to game environments. Section~3 reviews hierarchical planning approaches, with a particular focus on Hierarchical Task Networks and their use in encoding strategic knowledge for games. Section~4 examines Goal-Oriented Action Planning as a practical planning framework adopted in commercial game development. Section~5 surveys search-based planning approaches based on Monte Carlo Tree Search and state abstraction. Section~6 presents a comparative analysis of these paradigms, highlighting key trade-offs and design considerations. Finally, Section~7 discusses open challenges and future research directions, and Section~8 concludes the paper.

\section{Background}

AI planning is traditionally concerned with computing sequences of actions that transform an initial state of the world into a desired goal state. Classical planning formulations typically assume a discrete, fully observable, and deterministic environment, together with a static problem definition known in advance. Actions are specified through preconditions and effects, and planning is performed offline prior to execution. While this formulation has been highly successful in benchmark planning domains, its underlying assumptions rarely hold in interactive game environments.

Games differ from classical planning benchmarks in several important respects. Game environments are highly dynamic, with world states changing continuously due to physics simulation, non-player characters, and human player input. Planning and execution are often tightly interleaved, as agents must react within strict real-time constraints. In addition, games impose strong requirements on designer control and predictability, since agent behavior must remain interpretable, believable, and aligned with intended gameplay experiences. These characteristics make the direct application of classical planners impractical in most game settings \cite{kelly2007planning}.

Historically, game AI has relied on reactive control architectures such as finite state machines and, more recently, behavior trees. These approaches offer deterministic execution, low computational cost, and relative ease of debugging, which makes them attractive in production environments. However, they encode behavior procedurally rather than declaratively, resulting in limited flexibility and increasing authoring overhead as complexity grows. As game worlds scale, such systems become progressively harder to maintain, and agents struggle to adapt to situations not explicitly anticipated during design.

Planning-based approaches address these limitations by explicitly representing goals, actions, and world state, allowing agents to reason about future behavior rather than executing fixed control flows. In games, planning is rarely performed as a single offline computation. Instead, plans are often partial, continuously revised, or generated incrementally during execution. This shift from offline planning to online decision making represents a central adaptation of planning techniques to interactive environments \cite{neufeld2017htn}.

Several planning paradigms have been adapted to meet the constraints of games. Hierarchical planning methods, particularly Hierarchical Task Networks (HTNs), introduce structured decompositions that allow designers to encode domain knowledge and high-level strategies while retaining flexibility during execution. Goal-Oriented Action Planning (GOAP) adopts a flatter representation that emphasizes modular actions and frequent replanning in support of reactive yet goal-directed behavior. Search-based approaches, including methods inspired by Monte Carlo Tree Search, treat planning as an online decision process and often rely on abstraction or sampling to cope with large state spaces \cite{xu2022elastic}.

Across these paradigms, planning in games is best understood not as a replacement for reactive control, but as a complementary mechanism. Practical game AI systems frequently combine planning with scripting, heuristics, and domain-specific constraints in order to balance autonomy, performance, and designer intent. Understanding how different planning approaches navigate these trade-offs provides the foundation for the detailed analysis presented in the following sections.


\section{Hierarchical Planning for Games}

Hierarchical planning has played a prominent role in the application of planning techniques to games, largely because it supports reasoning at multiple levels of abstraction. Unlike flat planning representations, hierarchical approaches decompose high-level objectives into progressively more concrete subtasks. This structure provides guidance over agent behavior while still allowing flexibility during execution. Within this family of approaches, Hierarchical Task Network (HTN) planning has received particular attention in the game AI literature.

In HTN planning, problems are formulated in terms of tasks rather than explicit goal states. High-level tasks represent strategic intentions and are decomposed into subtasks through the application of methods, eventually yielding primitive actions that can be executed in the game world. This formulation allows designers to encode domain knowledge directly into the planning model, constraining the space of possible plans while permitting variation in behavior. In game settings, this balance is important, as unconstrained autonomy can easily result in behavior that is unintelligible or undesirable from a design perspective.

Early work by Hoang et al.\ showed how HTN representations could be used to encode strategic knowledge for game agents and to support the reuse of plans across similar situations \cite{hoang2005hierarchical}. By organizing behavior hierarchically, agents were able to reason at an appropriate level of abstraction while still producing executable action sequences. This approach reduced planning complexity and contributed to more consistent strategic behavior across gameplay scenarios.

Kelly et al.\ later examined how HTN planning could be integrated into real-time video games, with particular attention to computational constraints and frequent changes in the game state \cite{kelly2007planning}. Their approach emphasized incremental planning and execution rather than offline plan generation, allowing agents to interleave planning with action. This work highlighted an important requirement for HTNs in games, namely the ability to suspend, revise, or discard partial plans as conditions change.

The challenges associated with highly dynamic environments were further explored by Neufeld et al.\ in the \emph{HTN Fighter} system, which was designed for fast-paced combat scenarios \cite{neufeld2017htn}. In this system, replanning occurred frequently and was made tractable by limiting decomposition depth and prioritizing reactive responses when necessary. The results demonstrate that hierarchical structure and real-time responsiveness are not mutually exclusive, provided that planning decisions are tightly coupled to execution.

Taken together, these systems illustrate a characteristic trade-off in HTN-based game AI. Designers retain a high degree of control by specifying allowable behaviors through task decompositions, while agents retain limited autonomy by selecting among alternative methods or recomputing partial plans at runtime. This makes HTNs particularly suitable for games that require long-term strategy, coordination among multiple agents, or adherence to narrative and design constraints.

At the same time, HTN-based approaches introduce notable limitations. Developing and maintaining hierarchical task models can be labor-intensive, and agent behavior is highly dependent on the quality and completeness of the provided domain knowledge. Overly restrictive hierarchies may reduce behavioral diversity, while overly permissive ones can undermine predictability. These limitations motivate the consideration of alternative planning paradigms that place greater emphasis on flexibility and reactivity, which are discussed in the following section.


\section{Goal-Oriented Action Planning in Practice}

Goal-Oriented Action Planning (GOAP) was introduced as a practical alternative to large and increasingly complex finite state machines in game AI. Rather than organizing behavior around explicitly enumerated states and transitions, GOAP represents agent behavior in terms of goals, actions, and symbolic world-state conditions. This formulation allows agents to select actions dynamically based on their current objectives and the observed state of the environment.

In GOAP systems, actions are defined by preconditions and effects, while goals specify desired world-state properties. At runtime, a planner searches for a sequence of actions whose combined effects satisfy the selected goal. Unlike hierarchical approaches, GOAP typically relies on a flat action representation and frequent replanning, rather than predefined task decompositions. This design choice reduces authoring complexity and supports rapid adaptation to changing conditions.

A well-known application of GOAP was presented by Orkin in the commercial game \emph{F.E.A.R.}, where the approach was adopted to replace large finite state machines that had become difficult to maintain \cite{orkin2006three}. In this context, GOAP enabled non-player characters to exhibit context-sensitive behaviors such as seeking cover, coordinating with teammates, or advancing toward tactical objectives, without requiring designers to script all possible behavior transitions explicitly. By separating goals from actions, the system supported emergent behavior while remaining suitable for real-time execution.

From a practical standpoint, GOAP occupies a middle ground between purely reactive control architectures and more structured hierarchical planners. Compared to finite state machines and behavior trees, GOAP improves scalability and adaptability, as new actions and goals can be introduced without restructuring existing control logic. Compared to HTN-based approaches, GOAP reduces the need for explicit hierarchical modeling, but provides less direct support for encoding long-term strategic structure.

GOAP also exhibits limitations that affect its applicability. As the number of available actions increases, the flat action space can lead to higher planning costs, particularly when replanning is performed frequently. In addition, the absence of an explicit hierarchy makes it more difficult to represent complex strategies or long-term narrative constraints. In practice, GOAP systems are often augmented with heuristics, goal prioritization mechanisms, or domain-specific constraints to maintain performance and behavioral coherence.

Overall, GOAP has proven to be an effective and widely adopted planning framework in commercial game development, especially for agents operating in dynamic and tactical environments. Its emphasis on modular actions and frequent replanning makes it well suited for real-time games that demand responsive behavior. At the same time, its limitations in representing long-term structure motivate the exploration of alternative planning approaches, which are discussed in the following section.


\section{Search-Based Planning with State Abstraction}

Search-based methods constitute a distinct approach to planning in games, particularly in domains characterized by large state spaces and limited opportunities for explicit modeling. Rather than relying on symbolic representations of actions and goals, search-based planning treats decision making as an online process of exploring possible future states and selecting actions based on their expected outcomes. This perspective aligns well with many game environments, where uncertainty, adversarial interactions, and real-time constraints make exhaustive planning infeasible.

Monte Carlo Tree Search (MCTS) has emerged as a prominent framework for search-based planning in games. MCTS incrementally constructs a search tree through simulated action sequences and uses statistical estimates to balance exploration and exploitation. Unlike classical planning algorithms, MCTS does not require a complete symbolic domain model and can operate with a generative model of state transitions. These properties have contributed to its success in games involving strategic decision making and stochastic outcomes.

Direct application of MCTS to complex game environments, however, presents significant challenges. Large state and action spaces can render naive search computationally expensive, particularly under strict time constraints. To address this issue, researchers have investigated abstraction techniques that reduce the effective complexity of the search space by grouping states or actions according to higher-level features. Abstraction allows planning to proceed at a coarser level of detail, trading precision for scalability and responsiveness.

Xu et al.\ proposed Elastic Monte Carlo Tree Search as an approach that dynamically adjusts the level of abstraction used during search \cite{xu2022elastic}. Rather than relying on a fixed abstraction scheme, their method adapts abstraction granularity based on the available computational budget and properties of the current game state. This flexibility enables agents to reason strategically when time permits, while still producing timely decisions when constraints are tight. The work illustrates how abstraction can be integrated directly into the planning process rather than treated as a separate preprocessing step.

Search-based planning differs fundamentally from symbolic planning approaches in how behavior is controlled. While HTNs and GOAP encode domain structure explicitly through tasks, actions, and goals, MCTS-based methods rely on simulation and evaluation to guide decision making. This reduces manual authoring effort but increases reliance on evaluation functions, rollout policies, and abstraction design. As a result, search-based planners tend to offer greater domain independence at the expense of interpretability and designer control.

In game settings, search-based planning is particularly well suited to domains where the state space is too large or uncertain for explicit symbolic modeling, such as real-time strategy games and complex simulations. At the same time, reliance on sampling and approximation can make it difficult to guarantee consistent or narratively coherent behavior. These trade-offs are examined more closely in the comparative analysis presented in the next section.


\section{Comparative Analysis and Synthesis}

The planning approaches discussed in the previous sections, namely hierarchical planning, goal-oriented action planning, and search-based planning, address the demands of game environments using markedly different assumptions and mechanisms. These differences concern how knowledge is represented, how decisions are generated, and how much control is retained by designers as opposed to autonomous agents. In this section, we compare the three paradigms along several dimensions that are particularly relevant to game AI and summarize the trade-offs that emerge from their use in practice.

\subsection{Representation and Knowledge Encoding}

HTN-based approaches rely on explicit, designer-authored representations of domain knowledge. Strategic intent and behavioral structure are encoded directly through hierarchical task decompositions, which provide strong guidance over agent behavior and support long-term coordination. This expressiveness comes at the cost of increased authoring effort. GOAP, by contrast, adopts a flatter symbolic representation in which actions and goals are defined independently, reducing structural complexity while still enabling goal-directed reasoning. Search-based planning methods avoid explicit symbolic representations altogether and instead depend on simulation, evaluation functions, and abstraction. While this reduces the need for manual modeling, it also makes resulting behavior harder to interpret and constrain.

\subsection{Reactivity and Adaptability}

Reactivity is a central strength of both GOAP and search-based approaches. In GOAP systems, frequent replanning enables agents to respond quickly to changes in the environment, which is particularly valuable in dynamic and tactical scenarios. Search-based methods achieve adaptability through online simulation and selection, allowing them to cope naturally with uncertainty and adversarial dynamics. HTN-based planners can also adapt at runtime, but typically within the boundaries imposed by their hierarchical structure. This constraint improves predictability, although it can limit responsiveness in rapidly changing situations unless replanning is carefully managed.

\subsection{Computational Considerations}

Real-time performance places strict limits on planning complexity in games. HTN planners address this challenge by constraining the search space through task decompositions, making planning tractable even in domains with rich behavior sets. GOAP systems trade this structural guidance for simplicity, which can lead to higher computational costs as the number of actions increases, particularly when replanning occurs frequently. Search-based planners face the greatest computational demands due to large state spaces, but abstraction and sampling techniques allow them to scale by accepting approximate solutions in exchange for timely decisions.

\subsection{Designer Control and Authoring Effort}

The degree of designer control varies substantially across the three paradigms. HTNs offer the strongest control, as designers explicitly define allowable behaviors and strategies through task hierarchies. GOAP provides a more balanced approach, allowing designers to specify actions and goals without prescribing complete behavior sequences. Search-based planning offers the least direct control, since behavior emerges from evaluation and simulation, making it more difficult to enforce narrative or stylistic constraints. These differences are reflected in authoring effort, which is typically highest for HTNs, moderate for GOAP, and lowest for search-based methods.

\subsection{Summary of Trade-Offs}

Table~\ref{tab:comparison} summarizes the key characteristics of the three planning paradigms discussed in this survey.

\begin{table*}[t]
    \centering
    \small
    \begin{tabular}{lccc}
        \hline
        \textbf{Dimension} & \textbf{HTN}           & \textbf{GOAP}  & \textbf{Search-Based}   \\
        \hline
        Knowledge Encoding & Explicit, hierarchical & Symbolic, flat & Implicit, evaluative    \\
        Reactivity         & Moderate               & High           & High                    \\
        Long-Term Strategy & Strong                 & Limited        & Emergent                \\
        Designer Control   & High                   & Medium         & Low                     \\
        Authoring Effort   & High                   & Medium         & Low                     \\
        Scalability        & Moderate               & Moderate       & High (with abstraction) \\
        Interpretability   & High                   & Medium         & Low                     \\
        \hline
    \end{tabular}
    \caption{Comparison of planning paradigms in games across key dimensions.}
    \label{tab:comparison}
\end{table*}

Overall, no single planning paradigm dominates across all criteria. Hierarchical planning excels in domains that demand strategic consistency, coordination, and strong designer control. GOAP offers a pragmatic compromise between structure and flexibility, making it attractive for real-time and tactical gameplay. Search-based planning approaches are well suited to large and complex domains where explicit modeling is impractical, but they trade interpretability and control for scalability. These differences highlight the importance of selecting planning techniques based on the specific requirements of the game domain and motivate the exploration of hybrid and adaptive approaches discussed in the following section.


\section{Open Challenges and Research Directions}

Despite the demonstrated success of planning techniques in a wide range of game genres, several open challenges remain. These challenges arise not only from technical limitations, but also from the unique design and production constraints that characterize games as interactive systems. Addressing them is essential for advancing the practical impact of planning-based game AI.

A persistent challenge concerns the cost of authoring and maintaining planning models. Hierarchical approaches, in particular, require substantial manual effort to construct and refine task decompositions, while GOAP systems rely on carefully designed action sets and goal definitions. Although these representations offer valuable structure and control, their development remains time-consuming and error-prone. Reducing authoring overhead, either through improved tooling or through partial automation, remains an important research direction.

Another open issue relates to the integration of planning with learning. Most planning systems used in games rely on hand-crafted models, evaluation functions, or abstractions. While this supports predictability and designer control, it limits the ability of agents to adapt beyond predefined behaviors. Learning-based methods offer the potential to acquire models, heuristics, or abstractions from data, but combining them with planning raises questions about stability, interpretability, and controllability. Developing hybrid approaches that leverage learning without sacrificing the benefits of structured planning remains an active area of interest.

Evaluation and benchmarking also present significant challenges. Unlike classical planning domains, games vary widely in mechanics, objectives, and success criteria. Agent performance is often judged not only by effectiveness, but also by qualities such as believability, diversity of behavior, and player experience. As a result, comparing planning approaches across games is difficult, and standardized benchmarks remain limited. Establishing evaluation methodologies that capture both technical performance and design-oriented criteria would facilitate more systematic comparison of planning techniques in games.

Scalability under real-time constraints continues to be a central concern. While abstraction and sampling have enabled planning in increasingly complex environments, guaranteeing timely responses remains difficult as state and action spaces grow. This challenge is particularly pronounced in multi-agent settings, where coordination and interaction further increase complexity. Research into adaptive computation, hierarchical abstraction, and resource-aware planning may help address these issues.

Finally, the relationship between planning systems and game design raises broader questions about agency and control. Designers often wish to balance autonomous behavior with narrative structure, pacing, and aesthetic intent. Planning systems that are too rigid risk producing repetitive behavior, while overly flexible systems may undermine narrative coherence or gameplay balance. Understanding how planning techniques can better support designer intent, rather than merely replace scripted control, represents an important direction for future work.

Taken together, these challenges suggest that the future of planning in games is unlikely to be defined by a single dominant paradigm. Instead, progress will likely emerge from hybrid approaches that combine hierarchical structure, goal-driven reasoning, search-based decision making, and learning-based adaptation. Exploring how these components can be integrated in a principled and practical manner remains a promising avenue for continued research.


\section{Conclusion}

This paper has surveyed planning-based approaches for game AI, focusing on hierarchical planning, goal-oriented action planning, and search-based planning with abstraction. Each paradigm reflects a different response to the challenges posed by game environments, including real-time constraints, dynamic state evolution, and the need to balance agent autonomy with designer control. Rather than treating planning as a single unified technique, the literature reveals a spectrum of approaches shaped by practical considerations as much as by theoretical ones.

Hierarchical Task Network planning offers strong structure and interpretability, making it well suited for domains that require long-term strategy and explicit designer guidance. Goal-Oriented Action Planning provides a more flexible and lightweight alternative that has proven effective in commercial settings, particularly where responsiveness and modularity are priorities. Search-based planning approaches, especially those based on Monte Carlo Tree Search, emphasize scalability and domain independence, enabling decision making in large and uncertain state spaces at the cost of reduced transparency and direct control.

The comparative analysis highlights that no single planning paradigm is universally optimal for all game scenarios. Instead, the suitability of a given approach depends on factors such as the desired level of designer involvement, computational constraints, and the nature of the gameplay experience. In practice, successful game AI systems often combine elements from multiple paradigms, integrating planning with reactive control, heuristics, and domain-specific knowledge.

Overall, planning remains a valuable and evolving component of game AI research. While significant progress has been made in adapting planning techniques to the demands of interactive environments, important challenges related to authoring effort, scalability, evaluation, and integration with learning persist. Addressing these challenges will be essential for advancing the role of planning in future games and for bridging the gap between academic research and practical game development.


\bibliographystyle{aaai25}
\bibliography{aaai25}

\end{document}
