%release 2025.0
% !TEX root = main.tex
\documentclass[letterpaper]{article} % DO NOT CHANGE THIS
\usepackage{aaai25}  % DO NOT CHANGE THIS
\usepackage{times}  % DO NOT CHANGE THIS
\usepackage{helvet}  % DO NOT CHANGE THIS
\usepackage{courier}  % DO NOT CHANGE THIS
\usepackage[hyphens]{url}  % DO NOT CHANGE THIS
\usepackage{graphicx} % DO NOT CHANGE THIS
\urlstyle{rm} % DO NOT CHANGE THIS
\def\UrlFont{\rm}  % DO NOT CHANGE THIS
\usepackage{natbib}  % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT
\usepackage{caption} % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT
\frenchspacing  % DO NOT CHANGE THIS
\setlength{\pdfpagewidth}{8.5in}  % DO NOT CHANGE THIS
\setlength{\pdfpageheight}{11in}  % DO NOT CHANGE THIS
%
% These are recommended to typeset algorithms but not required. See the subsubsection on algorithms. Remove them if you don't have algorithms in your paper.
\usepackage{algorithm}
\usepackage{algorithmic}

%
% These are are recommended to typeset listings but not required. See the subsubsection on listing. Remove this block if you don't have listings in your paper.
\usepackage{newfloat}
\usepackage{listings}
\DeclareCaptionStyle{ruled}{labelfont=normalfont,labelsep=colon,strut=off} % DO NOT CHANGE THIS
\lstset{%
	basicstyle={\footnotesize\ttfamily},% footnotesize acceptable for monospace
	numbers=left,numberstyle=\footnotesize,xleftmargin=2em,% show line numbers, remove this entire line if you don't want the numbers.
	aboveskip=0pt,belowskip=0pt,%
	showstringspaces=false,tabsize=2,breaklines=true}
\floatstyle{ruled}
\newfloat{listing}{tb}{lst}{}
\floatname{listing}{Listing}
%
% Keep the \pdfinfo as shown here. There's no need
% for you to add the /Title and /Author tags.
\pdfinfo{
/TemplateVersion (2025.1)
}

% DISALLOWED PACKAGES
% \usepackage{authblk} -- This package is specifically forbidden
% \usepackage{balance} -- This package is specifically forbidden
% \usepackage{color (if used in text)
% \usepackage{CJK} -- This package is specifically forbidden
% \usepackage{float} -- This package is specifically forbidden
% \usepackage{flushend} -- This package is specifically forbidden
% \usepackage{fontenc} -- This package is specifically forbidden
% \usepackage{fullpage} -- This package is specifically forbidden
% \usepackage{geometry} -- This package is specifically forbidden
% \usepackage{grffile} -- This package is specifically forbidden
% \usepackage{hyperref} -- This package is specifically forbidden
% \usepackage{navigator} -- This package is specifically forbidden
% (or any other package that embeds links such as navigator or hyperref)
% \indentfirst} -- This package is specifically forbidden
% \layout} -- This package is specifically forbidden
% \multicol} -- This package is specifically forbidden
% \nameref} -- This package is specifically forbidden
% \usepackage{savetrees} -- This package is specifically forbidden
% \usepackage{setspace} -- This package is specifically forbidden
% \usepackage{stfloats} -- This package is specifically forbidden
% \usepackage{tabu} -- This package is specifically forbidden
% \usepackage{titlesec} -- This package is specifically forbidden
% \usepackage{tocbibind} -- This package is specifically forbidden
% \usepackage{ulem} -- This package is specifically forbidden
% \usepackage{wrapfig} -- This package is specifically forbidden
% DISALLOWED COMMANDS
% \nocopyright -- Your paper will not be published if you use this command
% \addtolength -- This command may not be used
% \balance -- This command may not be used
% \baselinestretch -- Your paper will not be published if you use this command
% \clearpage -- No page breaks of any kind may be used for the final version of your paper
% \columnsep -- This command may not be used
% \newpage -- No page breaks of any kind may be used for the final version of your paper
% \pagebreak -- No page breaks of any kind may be used for the final version of your paperr
% \pagestyle -- This command may not be used
% \tiny -- This is not an acceptable font size.
% \vspace{- -- No negative value may be used in proximity of a caption, figure, table, section, subsection, subsubsection, or reference
% \vskip{- -- No negative value may be used to alter spacing above or below a caption, figure, table, section, subsection, subsubsection, or reference

\setcounter{secnumdepth}{2} %May be changed to 1 or 2 if section numbers are desired.

% The file aaai25.sty is the style file for AAAI Press
% proceedings, working notes, and technical reports.
%

% Title

% Your title must be in mixed case, not sentence case.
% That means all verbs (including short verbs like be, is, using,and go),
% nouns, adverbs, adjectives should be capitalized, including both words in hyphenated terms, while
% articles, conjunctions, and prepositions are lower case unless they
% directly follow a colon or long dash
\title{Planning Approaches for Game Artificial Intelligence: A Survey}
\author{
    %Authors
    % All authors must be in the same font size and format.
    % Written by AAAI Press Staff\textsuperscript{\rm 1}\thanks{With help from the AAAI Publications Committee.}\\
    % AAAI Style Contributions by Samanth Nanda Kumar,\\
    % J. Scott Penberthy,
    % George Ferguson,
    % Hans Guesgen,
    % Francisco Cruz\equalcontrib,
    % Marc Pujol-Gonzalez\equalcontrib
    Samanth Nanda Kumar \\
    Universität Stuttgart \\
    \texttt{st193225@stud.uni-stuttgart.de}
}
% \affiliations{
%     %Afiliations
%     \textsuperscript{\rm 1}Association for the Advancement of Artificial Intelligence\\
%     % If you have multiple authors and multiple affiliations
%     % use superscripts in text and roman font to identify them.
%     % For example,

%     % Sunil Issar\textsuperscript{\rm 2}, 
%     % J. Scott Penberthy\textsuperscript{\rm 3}, 
%     % George Ferguson\textsuperscript{\rm 4},
%     % Hans Guesgen\textsuperscript{\rm 5}
%     % Note that the comma should be placed after the superscript

%     1101 Pennsylvania Ave, NW Suite 300\\
%     Washington, DC 20004 USA\\
%     % email address must be in roman text type, not monospace or sans serif
%     proceedings-questions@aaai.org
% %
% % See more examples next
% }

%Example, Single Author, ->> remove \iffalse,\fi and place them surrounding AAAI title to use it
\iffalse
\title{My Publication Title --- Single Author}
\author {
    Author Name
}
\affiliations{
    Affiliation\\
    Affiliation Line 2\\
    name@example.com
}
\fi

\iffalse
%Example, Multiple Authors, ->> remove \iffalse,\fi and place them surrounding AAAI title to use it
\title{My Publication Title --- Multiple Authors}
\author {
    % Authors
    First Author Name\textsuperscript{\rm 1,\rm 2},
    Second Author Name\textsuperscript{\rm 2},
    Third Author Name\textsuperscript{\rm 1}
}
\affiliations {
    % Affiliations
    \textsuperscript{\rm 1}Affiliation 1\\
    \textsuperscript{\rm 2}Affiliation 2\\
    firstAuthor@affiliation1.com, secondAuthor@affilation2.com, thirdAuthor@affiliation1.com
}
\fi


% REMOVE THIS: bibentry
% This is only needed to show inline citations in the guidelines document. You should not need it and can safely delete it.
\usepackage{bibentry}
% END REMOVE bibentry

\begin{document}

\maketitle

\begin{abstract}
    Artificial intelligence planning has long been explored as a principled approach for generating goal-directed behavior in games. Unlike purely reactive control architectures, planning-based methods explicitly reason about actions, goals, and their consequences, enabling more flexible and adaptive agent behavior. However, the application of planning in games introduces unique challenges, including real-time constraints, highly dynamic environments, and the need for designer control. This paper presents a literature survey of planning approaches applied to games, focusing on hierarchical symbolic planning, goal-oriented action planning, and search-based planning with state abstraction. We analyze representative methods from both academic research and industry practice, compare their strengths and limitations, and discuss open challenges that motivate future research in game AI planning.
\end{abstract}

% Uncomment the following to link to your code, datasets, an extended version or similar.
%
% \begin{links}
%     \link{Code}{https://aaai.org/example/code}
%     \link{Datasets}{https://aaai.org/example/datasets}
%     \link{Extended version}{https://aaai.org/example/extended-version}
% \end{links}

\section{Introduction}

Digital games constitute a challenging and diverse domain for artificial intelligence research. Contemporary games combine large state and action spaces with real-time decision making, stochastic outcomes, and environments that evolve continuously in response to both system dynamics and human player behavior. For these reasons, games have long served not only as experimental testbeds for AI research, but also as application domains in which theoretical methods must be adapted to strict performance, robustness, and design constraints. Within this context, AI planning has emerged as a principled approach for generating goal-directed behavior, providing an alternative to purely reactive or heavily scripted control architectures \cite{hoang2005hierarchical}.

Traditional game AI techniques, such as finite state machines and behavior trees, remain widely used due to their simplicity, predictability, and low computational overhead. However, as game worlds expand in scope and agent responsibilities become more complex, these approaches often struggle to scale. Authoring effort increases substantially, behavior logic becomes difficult to maintain, and agents exhibit limited flexibility when confronted with situations not explicitly anticipated during design. Planning-based approaches seek to address these limitations by explicitly modeling goals, actions, and state transitions, thereby enabling agents to reason about future consequences and revise their behavior dynamically during execution \cite{kelly2007planning}. As a result, planning techniques have been explored across a broad range of game genres, including fast-paced action games as well as large-scale strategy and simulation environments.

Despite their conceptual appeal, planning techniques face significant challenges when applied to games. Classical planning formulations typically assume static environments, offline computation, and complete knowledge of the world state. In contrast, game environments are subject to frequent and unpredictable changes, tight real-time constraints, and strong requirements for designer oversight to ensure believable and controllable agent behavior. These discrepancies have motivated the development of planning approaches that are explicitly tailored to the demands of games, rather than direct applications of classical planners \cite{neufeld2017htn}.

One prominent line of work focuses on hierarchical planning, particularly Hierarchical Task Network (HTN) methods, which decompose complex behaviors into structured subtasks while preserving designer-authored strategic knowledge. HTN-based approaches have proven effective in games that require long-term planning and coordination, while still allowing adaptation during execution. In parallel, Goal-Oriented Action Planning (GOAP) has been adopted in commercial game development as a more lightweight and flexible alternative to large finite state machines. By decoupling goals from actions and relying on frequent replanning, GOAP enables agents to respond adaptively to changing world states, as demonstrated in commercial titles \cite{orkin2006three}.

More recently, search-based planning approaches inspired by Monte Carlo Tree Search (MCTS) have been investigated as a means of handling large decision spaces under uncertainty. These methods typically rely on abstraction techniques to manage computational complexity, trading exact reasoning for scalable approximation. Such approaches are particularly relevant in strategy and simulation games, where exhaustive planning is infeasible and adaptability is essential \cite{xu2022elastic}.

The remainder of this paper is organized as follows. Section~2 provides background on AI planning and discusses the challenges that arise when applying classical planning techniques to game environments. Section~3 reviews hierarchical planning approaches, with a particular focus on Hierarchical Task Networks and their use in encoding strategic knowledge for games. Section~4 examines Goal-Oriented Action Planning as a practical planning framework adopted in commercial game development. Section~5 surveys search-based planning approaches based on Monte Carlo Tree Search and state abstraction. Section~6 presents a comparative analysis of these paradigms, highlighting key trade-offs and design considerations. Finally, Section~7 discusses open challenges and future research directions, and Section~8 concludes the paper.

\section{Background: AI Planning in Games}

This section provides the necessary background to situate planning-based approaches within the broader landscape of game AI. Rather than presenting a comprehensive overview of planning techniques, the focus is on clarifying how planning differs from other control paradigms commonly used in games and on identifying the characteristics of game environments that shape the design and application of planning methods.

\subsection{Planning vs.\ Reactive and Learning-Based Game AI}

Historically, game AI has been dominated by reactive control architectures, most notably finite state machines and, more recently, behavior trees. These approaches organize behavior procedurally through explicitly defined states, transitions, or control flows. Their appeal lies in their predictability, low computational overhead, and relative ease of debugging, all of which are important considerations in production environments. As a result, they remain widely used in commercial games.

However, purely reactive systems exhibit limitations as game complexity increases. As the number of states or behaviors grows, authoring and maintaining control logic becomes increasingly difficult. Reactive systems also struggle to generalize beyond situations explicitly anticipated during design, leading to brittle behavior when agents encounter novel circumstances. These limitations have motivated the exploration of alternative approaches that allow agents to reason more explicitly about goals and future consequences.

Planning-based approaches occupy a distinct position within the game AI spectrum. By representing goals, actions, and world state explicitly, planning systems enable agents to construct and revise action sequences at runtime, rather than following fixed control structures. In games, planning is rarely performed as a single offline computation. Instead, planning and execution are typically interleaved, with partial plans generated, adapted, or discarded as the game state evolves. This shift toward online and incremental planning represents a key adaptation of classical planning ideas to interactive environments \cite{neufeld2017htn}.

Learning-based methods have also become increasingly prominent in game AI, particularly in contexts where large amounts of data are available. While learning can complement planning by providing models, heuristics, or policies, it often raises concerns related to predictability and designer control. In practice, planning is frequently used alongside reactive and learning-based components, rather than as a replacement, allowing designers to balance autonomy with control and interpretability.

\subsection{Characteristics of Games Relevant to Planning}

Games exhibit a number of characteristics that distinguish them from classical planning benchmarks and strongly influence how planning techniques must be applied. One important distinction concerns timing. Many games operate under strict real-time constraints, requiring agents to act within fixed frame budgets, while others adopt turn-based structures that allow more deliberation. Planning methods must therefore accommodate varying time horizons and computational budgets.

Uncertainty is another defining feature of games. Some games are largely deterministic, while others involve stochastic outcomes, hidden information, or adversarial opponents whose actions cannot be predicted in advance. These factors complicate planning by introducing uncertainty into state transitions and action outcomes. As a result, planning techniques in games often rely on frequent replanning, abstraction, or sampling rather than exhaustive reasoning.

Games also vary in terms of agency and interaction. Single-agent settings simplify planning by allowing agents to reason in isolation, whereas multi-agent games introduce additional challenges related to coordination, competition, and interference. In multi-agent environments, planning decisions must account for the actions of other agents, further increasing complexity.

Finally, game environments are typically highly dynamic and only partially observable. World states may change continuously due to physics simulation, non-player characters, and player input. In addition, agents may have incomplete or noisy information about the environment. These properties undermine assumptions of static and fully observable worlds that underlie many classical planning formulations, making direct application impractical \cite{kelly2007planning}.

Taken together, these characteristics explain why planning techniques used in games differ substantially from those developed for classical planning benchmarks. Rather than producing complete plans offline, game-oriented planning approaches emphasize incremental reasoning, adaptability, and close integration with execution. These considerations motivate the specialized planning paradigms examined in the following sections.


\section{Hierarchical Planning for Games}

The characteristics of games discussed in the previous section motivate planning approaches that can balance adaptability with designer control. Hierarchical planning has emerged as a particularly influential paradigm in this context, as it allows reasoning at multiple levels of abstraction while constraining agent behavior in ways that remain compatible with game design requirements. This section examines Hierarchical Task Network (HTN) planning as a representative hierarchical approach and discusses how it has been adapted to meet the practical constraints of games.

\subsection{Hierarchical Task Networks}

Hierarchical Task Network planning differs from classical goal-based planning by formulating problems in terms of tasks rather than explicit goal states. In an HTN, high-level tasks represent abstract objectives, which are decomposed into subtasks through the application of methods. This process continues until primitive actions are produced that can be executed directly in the game world. The hierarchy implicitly encodes control knowledge, guiding the planner toward behavior sequences that are meaningful within the domain.

For games, this task-centered formulation offers several advantages. By embedding domain knowledge into task decompositions, designers can restrict the space of admissible plans, ensuring that generated behavior aligns with intended gameplay. At the same time, the hierarchical structure supports reasoning at an appropriate level of abstraction, allowing agents to make strategic decisions without committing prematurely to low-level actions. As a result, HTNs are well suited to domains that require long-term planning, coordination, or narrative coherence.

\subsection{Encoding Strategic Knowledge with HTNs}

Early work by Hoang et al.\ demonstrated how HTN representations could be used to encode strategic knowledge for game agents in a reusable and modular form \cite{hoang2005hierarchical}. In their approach, high-level strategies were captured as abstract tasks, while methods specified alternative ways of realizing these strategies under different conditions. This structure allowed agents to reuse previously generated plans and to adapt them to new situations without replanning from scratch.

Encoding strategy hierarchically offers clear benefits for scalability and maintainability. By decomposing behavior into modular components, designers can modify or extend specific parts of the hierarchy without redesigning the entire planning model. In comparison to flat planning representations, this approach reduces combinatorial complexity and supports more consistent strategic behavior across gameplay scenarios.

However, these benefits come with trade-offs. The effectiveness of HTN planning depends heavily on the quality and completeness of the encoded domain knowledge. Authoring task hierarchies requires substantial expertise and effort, and omissions or overly restrictive decompositions can limit behavioral diversity. These limitations highlight an inherent tension between control and flexibility that recurs across HTN-based game AI.

\subsection{HTN Planning under Game Constraints}

While early HTN approaches emphasized strategic encoding, subsequent work addressed the practical constraints imposed by real-time game environments. Kelly et al.\ investigated how HTN planning could be integrated into video games where planning and execution must occur under tight computational budgets \cite{kelly2007planning}. Rather than generating complete plans offline, their approach emphasized incremental planning, allowing agents to interleave planning with action execution.

This shift from offline to online planning marked an important adaptation of HTNs to games. By monitoring execution and revising plans when necessary, agents could respond to unexpected changes in the game state without discarding hierarchical structure altogether. Compared to static planning approaches, this enabled greater responsiveness while preserving the benefits of strategic decomposition.

At the same time, online HTN planning introduces additional complexity. Monitoring plan validity, deciding when to replan, and limiting computational overhead all require careful design choices. These challenges underscore the difficulty of applying hierarchical planning in environments where real-time responsiveness is essential.

\subsection{HTNs in Highly Dynamic Games}

The challenges of dynamic and fast-paced game environments were further explored by Neufeld et al.\ in the \emph{HTN Fighter} system \cite{neufeld2017htn}. Designed for combat scenarios with frequent and unpredictable state changes, the system relied on frequent replanning and shallow task decompositions to maintain responsiveness. Rather than pursuing optimal plans, the focus shifted toward producing timely and robust behavior.

This work highlights a key trade-off in hierarchical planning for games. Deep hierarchies and extensive deliberation support strategic optimality but are poorly suited to highly dynamic environments. Conversely, limiting decomposition depth and prioritizing reactive responses improves responsiveness at the cost of long-term optimality. The design of \emph{HTN Fighter} illustrates how HTNs can be adapted along this spectrum, depending on the demands of the game.

Across these studies, a consistent pattern emerges. HTN-based approaches offer strong designer control and support strategic reasoning, but their effectiveness depends on careful adaptation to game-specific constraints. Static environments favor deeper hierarchies and offline reasoning, while dynamic environments require online planning, frequent replanning, and reduced hierarchical depth. These trade-offs motivate comparison with alternative planning paradigms that place greater emphasis on flexibility and reactivity, which are examined in the following section.


\section{Goal-Oriented Action Planning in Practice}

While hierarchical planning emphasizes structure and explicit strategic guidance, its authoring complexity and sensitivity to domain modeling can limit its applicability in some game contexts. In response to these challenges, Goal-Oriented Action Planning (GOAP) emerged as a more lightweight planning framework designed to manage behavioral complexity without relying on deep hierarchical representations. This section examines GOAP as a practical alternative to traditional reactive systems and situates its adoption within the constraints of commercial game development.

\subsection{From Finite State Machines to Declarative Planning}

The development of GOAP was motivated in large part by the limitations of finite state machines (FSMs) as game AI systems grew in scale. FSM-based architectures encode behavior procedurally through explicit states and transitions, which become increasingly difficult to author and maintain as the number of behaviors increases. As transitions proliferate, the resulting control logic becomes brittle and hard to extend, particularly when new behaviors must interact with existing ones.

GOAP addresses this problem by shifting from procedural control flow to a declarative representation of behavior. Rather than specifying how agents transition between states, designers define actions in terms of preconditions and effects, along with goals that describe desired world-state properties. At runtime, the planner selects and sequences actions based on the current state and the active goal. This separation of goals and actions reduces coupling between behaviors and allows agents to respond flexibly to changing circumstances without requiring explicit transition logic.

In contrast to HTN planning, GOAP typically relies on a flat action space rather than hierarchical task decomposition. This design choice simplifies authoring and supports rapid adaptation, but it also limits the planner’s ability to reason explicitly about long-term strategy. As a result, GOAP is particularly well suited to tactical decision making in dynamic environments.

\subsection{GOAP in Commercial Games}

A prominent application of GOAP was presented by Orkin in the context of the commercial first-person shooter \emph{F.E.A.R.} \cite{orkin2006three}. In this setting, GOAP was introduced to replace large FSM-based systems that had become difficult to scale and maintain within a AAA production pipeline. The planner used an A*-based search over actions, treating action costs as a heuristic measure of desirability.

By decoupling goals from actions, the system allowed non-player characters to exhibit context-sensitive behavior without requiring designers to script all possible scenarios explicitly. Agents could select actions such as seeking cover, flanking enemies, or coordinating with allies based on the current state of the environment and their active goals. Frequent replanning enabled agents to respond to changes in real time, producing behavior that appeared adaptive and coherent from the player’s perspective.

The significance of this approach lies not only in its technical design, but also in its successful deployment in a commercial setting. GOAP demonstrated that planning-based techniques could be integrated into real-time games under strict performance constraints, while remaining accessible to designers and compatible with production workflows. This helped establish GOAP as a practical planning framework beyond academic prototypes.

\subsection{Strengths and Limitations of GOAP}

GOAP offers several strengths that have contributed to its adoption in practice. Its declarative representation improves modularity and scalability compared to FSM-based systems, allowing new actions and goals to be introduced with minimal changes to existing behavior logic. Frequent replanning increases robustness in dynamic environments, and the explicit representation of goals and actions supports debugging and tuning by designers.

At the same time, GOAP exhibits limitations that constrain its applicability. As the number of available actions grows, the flat action space can lead to increased planning costs, particularly in scenarios that require frequent replanning. In addition, the absence of hierarchical structure makes it difficult to encode long-term strategy or high-level narrative constraints explicitly. Compared to HTN-based approaches, GOAP offers less direct support for strategic reasoning and designer-authored abstraction.

In practice, these limitations are often mitigated through the use of heuristics, goal prioritization schemes, or domain-specific constraints. Nevertheless, they highlight a recurring trade-off between flexibility and structure that distinguishes GOAP from hierarchical planning. These considerations motivate the exploration of alternative planning paradigms that emphasize scalability and abstraction, which are examined in the following section.


\section{Search-Based Planning with State Abstraction}

The planning approaches discussed so far rely on explicit symbolic representations of goals, actions, and domain knowledge. While such representations support interpretability and designer control, they can be difficult to scale to environments with large state spaces or complex dynamics. Search-based planning offers an alternative perspective by framing decision making as an online process of exploration and evaluation, rather than symbolic reasoning over predefined models. This section examines search-based planning methods for games, with a particular focus on Monte Carlo Tree Search and the role of state abstraction.

\subsection{Monte Carlo Tree Search for Games}

Monte Carlo Tree Search (MCTS) has emerged as a widely used decision-making framework in games, particularly in domains characterized by uncertainty, adversarial interaction, and large branching factors. Unlike symbolic planners, which construct plans by reasoning over action models and goal descriptions, MCTS builds a search tree incrementally by simulating sequences of actions and estimating their expected outcomes. Decisions are guided by a balance between exploration of new possibilities and exploitation of known promising actions.

From a planning perspective, MCTS can be understood as an online planning method that evaluates future trajectories rather than generating explicit plans. It does not require a complete symbolic model of the domain and can operate with a generative model of state transitions. This property makes MCTS attractive in game settings where modeling all relevant dynamics explicitly is impractical. However, the absence of explicit goals and symbolic structure also distinguishes MCTS from planning approaches such as HTNs and GOAP, shifting emphasis toward evaluation and simulation.

\subsection{State Abstraction in Planning}

A central challenge for search-based planning in games is the combinatorial explosion of state and action spaces. As games increase in complexity, exhaustive search quickly becomes infeasible, particularly under real-time constraints. State abstraction addresses this challenge by reducing the effective complexity of the search space, either by grouping similar states or by reasoning at higher levels of granularity.

Abstraction can be introduced in different ways. Domain-dependent abstractions rely on hand-crafted knowledge about the game structure, allowing planners to ignore irrelevant details and focus on strategically meaningful features. Domain-independent abstractions aim to reduce complexity without relying on extensive prior knowledge, often through generic feature selection or sampling strategies. While domain-dependent abstraction can be highly effective, it reintroduces authoring effort and limits generality. Domain-independent approaches offer greater flexibility but may sacrifice precision or interpretability.

In the context of planning, abstraction enables agents to trade accuracy for responsiveness, allowing timely decisions even when exact reasoning is computationally prohibitive. This trade-off is particularly important in large strategy games and simulations, where planning horizons are long and the state space is vast.

\subsection{Elastic Monte Carlo Tree Search}

Xu et al.\ proposed Elastic Monte Carlo Tree Search as an approach that integrates abstraction directly into the search process \cite{xu2022elastic}. Rather than relying on a fixed level of abstraction, their method dynamically adjusts abstraction granularity based on the available computational budget and the characteristics of the current game state. When resources permit, the planner reasons at a finer level of detail; under tighter constraints, it operates on more abstract representations.

This dynamic adjustment allows the planner to balance strategic reasoning and real-time responsiveness more effectively than static abstraction schemes. In large strategy games, elastic abstraction enables agents to consider long-term consequences without committing to prohibitively expensive fine-grained search. Compared to symbolic planning approaches, Elastic MCTS reduces reliance on explicit domain modeling, while still supporting strategic decision making through adaptive abstraction.

\subsection{Discussion: Symbolic vs.\ Search-Based Planning}

The contrast between symbolic planning approaches, such as HTNs and GOAP, and search-based methods highlights several recurring trade-offs. Symbolic planners emphasize interpretability, designer control, and explicit representation of goals and actions. These properties support structured behavior and alignment with design intent but require significant authoring effort and careful domain modeling.

Search-based planners, by contrast, emphasize generality and scalability. By relying on simulation and evaluation rather than explicit symbolic structure, they reduce manual modeling requirements and can be applied across a wide range of domains. However, this generality comes at the cost of reduced transparency and limited direct control over behavior. Authoring effort shifts from defining actions and tasks to designing evaluation functions, abstractions, and rollout policies.

These differences suggest that symbolic and search-based planning approaches address complementary aspects of the planning problem in games. Symbolic methods are well suited to domains that require structured behavior and strong designer oversight, while search-based methods excel in large, uncertain environments where explicit modeling is impractical. Understanding how these approaches differ provides important context for the comparative analysis presented in the following section.


\section{Comparative Analysis and Synthesis}

The planning approaches discussed in the previous sections, namely hierarchical planning, goal-oriented action planning, and search-based planning, address the demands of game environments using markedly different assumptions and mechanisms. These differences concern how knowledge is represented, how decisions are generated, and how much control is retained by designers as opposed to autonomous agents. In this section, we compare the three paradigms along several dimensions that are particularly relevant to game AI and summarize the trade-offs that emerge from their use in practice.

\subsection{Representation and Knowledge Encoding}

HTN-based approaches rely on explicit, designer-authored representations of domain knowledge. Strategic intent and behavioral structure are encoded directly through hierarchical task decompositions, which provide strong guidance over agent behavior and support long-term coordination. This expressiveness comes at the cost of increased authoring effort. GOAP, by contrast, adopts a flatter symbolic representation in which actions and goals are defined independently, reducing structural complexity while still enabling goal-directed reasoning. Search-based planning methods avoid explicit symbolic representations altogether and instead depend on simulation, evaluation functions, and abstraction. While this reduces the need for manual modeling, it also makes resulting behavior harder to interpret and constrain.

\subsection{Reactivity and Adaptability}

Reactivity is a central strength of both GOAP and search-based approaches. In GOAP systems, frequent replanning enables agents to respond quickly to changes in the environment, which is particularly valuable in dynamic and tactical scenarios. Search-based methods achieve adaptability through online simulation and selection, allowing them to cope naturally with uncertainty and adversarial dynamics. HTN-based planners can also adapt at runtime, but typically within the boundaries imposed by their hierarchical structure. This constraint improves predictability, although it can limit responsiveness in rapidly changing situations unless replanning is carefully managed.

\subsection{Computational Considerations}

Real-time performance places strict limits on planning complexity in games. HTN planners address this challenge by constraining the search space through task decompositions, making planning tractable even in domains with rich behavior sets. GOAP systems trade this structural guidance for simplicity, which can lead to higher computational costs as the number of actions increases, particularly when replanning occurs frequently. Search-based planners face the greatest computational demands due to large state spaces, but abstraction and sampling techniques allow them to scale by accepting approximate solutions in exchange for timely decisions.

\subsection{Designer Control and Authoring Effort}

The degree of designer control varies substantially across the three paradigms. HTNs offer the strongest control, as designers explicitly define allowable behaviors and strategies through task hierarchies. GOAP provides a more balanced approach, allowing designers to specify actions and goals without prescribing complete behavior sequences. Search-based planning offers the least direct control, since behavior emerges from evaluation and simulation, making it more difficult to enforce narrative or stylistic constraints. These differences are reflected in authoring effort, which is typically highest for HTNs, moderate for GOAP, and lowest for search-based methods.

\subsection{Summary of Trade-Offs}

Table~\ref{tab:comparison} summarizes the key characteristics of the three planning paradigms discussed in this survey.

\begin{table*}[t]
    \centering
    \small
    \begin{tabular}{lccc}
        \hline
        \textbf{Dimension} & \textbf{HTN}           & \textbf{GOAP}  & \textbf{Search-Based}   \\
        \hline
        Knowledge Encoding & Explicit, hierarchical & Symbolic, flat & Implicit, evaluative    \\
        Reactivity         & Moderate               & High           & High                    \\
        Long-Term Strategy & Strong                 & Limited        & Emergent                \\
        Designer Control   & High                   & Medium         & Low                     \\
        Authoring Effort   & High                   & Medium         & Low                     \\
        Scalability        & Moderate               & Moderate       & High (with abstraction) \\
        Interpretability   & High                   & Medium         & Low                     \\
        \hline
    \end{tabular}
    \caption{Comparison of planning paradigms in games across key dimensions.}
    \label{tab:comparison}
\end{table*}

Overall, no single planning paradigm dominates across all criteria. Hierarchical planning excels in domains that demand strategic consistency, coordination, and strong designer control. GOAP offers a pragmatic compromise between structure and flexibility, making it attractive for real-time and tactical gameplay. Search-based planning approaches are well suited to large and complex domains where explicit modeling is impractical, but they trade interpretability and control for scalability. These differences highlight the importance of selecting planning techniques based on the specific requirements of the game domain and motivate the exploration of hybrid and adaptive approaches discussed in the following section.


\section{Open Challenges and Research Directions}

Although planning techniques have been applied successfully across a range of game genres, several open challenges remain. These challenges are not solely technical in nature, but arise from the broader design, production, and interaction constraints that distinguish games from other planning domains. Addressing them is critical for extending the practical impact of planning-based game AI.

One recurring challenge concerns the effort required to author and maintain planning models. Hierarchical approaches, in particular, depend on carefully constructed task decompositions, while GOAP systems require well-designed action sets and goal specifications. These representations provide valuable structure and designer control, but they are also time-consuming to develop and sensitive to modeling errors. As games evolve during development, maintaining consistency between planning models and game mechanics can become a substantial burden. Reducing this authoring cost, whether through improved tools, higher-level abstractions, or partial automation, remains an important direction for future work.

A closely related issue is the integration of planning with learning-based methods. Most planning systems used in games rely on hand-crafted models, heuristics, or abstractions, which supports predictability and interpretability but limits adaptability. Learning-based techniques offer the potential to acquire models, evaluation functions, or abstractions from data, but their integration with planning raises concerns about stability, transparency, and designer trust. Balancing the adaptability of learning with the control and structure provided by planning remains an open research problem, particularly in production environments where predictable behavior is essential.

Evaluation and benchmarking pose additional challenges. Unlike classical planning benchmarks, games vary widely in mechanics, objectives, and success criteria. Moreover, agent behavior is often judged along dimensions that are difficult to quantify, such as believability, behavioral diversity, and player experience. This diversity complicates direct comparison of planning approaches and limits the availability of standardized benchmarks. Developing evaluation methodologies that capture both technical performance and design-oriented qualities would support more systematic assessment of planning techniques in games.

Scalability under real-time constraints continues to be a central concern, especially as games grow in complexity. Abstraction and sampling have enabled planning in increasingly large state spaces, but guaranteeing timely responses remains difficult, particularly in multi-agent settings where coordination and interaction further increase computational demands. Approaches that adapt planning effort dynamically, based on available resources and gameplay context, represent a promising direction for addressing these constraints.

Finally, the interaction between planning systems and game design raises broader questions about agency and control. Designers must balance autonomous agent behavior with narrative structure, pacing, and aesthetic intent. Planning systems that are too restrictive risk producing repetitive or predictable behavior, while overly flexible systems may undermine narrative coherence or gameplay balance. Understanding how planning techniques can better support designer intent, rather than simply replacing scripted control, remains an important challenge.

Taken together, these issues suggest that the future of planning in games is unlikely to be defined by a single dominant approach. Instead, progress is likely to come from hybrid systems that combine hierarchical structure, goal-driven reasoning, search-based decision making, and learning-based adaptation. Exploring how these components can be integrated in a principled and practical manner remains a central research direction for planning-based game AI.


\section{Conclusion}

This paper has surveyed planning-based approaches for game AI, focusing on hierarchical planning, goal-oriented action planning, and search-based planning with abstraction. Each paradigm reflects a different response to the challenges posed by game environments, including real-time constraints, dynamic state evolution, and the need to balance agent autonomy with designer control. Rather than treating planning as a single unified technique, the literature reveals a spectrum of approaches shaped by practical considerations as much as by theoretical ones.

Hierarchical Task Network planning offers strong structure and interpretability, making it well suited for domains that require long-term strategy and explicit designer guidance. Goal-Oriented Action Planning provides a more flexible and lightweight alternative that has proven effective in commercial settings, particularly where responsiveness and modularity are priorities. Search-based planning approaches, especially those based on Monte Carlo Tree Search, emphasize scalability and domain independence, enabling decision making in large and uncertain state spaces at the cost of reduced transparency and direct control.

The comparative analysis highlights that no single planning paradigm is universally optimal for all game scenarios. Instead, the suitability of a given approach depends on factors such as the desired level of designer involvement, computational constraints, and the nature of the gameplay experience. In practice, successful game AI systems often combine elements from multiple paradigms, integrating planning with reactive control, heuristics, and domain-specific knowledge.

Overall, planning remains a valuable and evolving component of game AI research. While significant progress has been made in adapting planning techniques to the demands of interactive environments, important challenges related to authoring effort, scalability, evaluation, and integration with learning persist. Addressing these challenges will be essential for advancing the role of planning in future games and for bridging the gap between academic research and practical game development.


\bibliographystyle{aaai25}
\bibliography{aaai25}

\end{document}
