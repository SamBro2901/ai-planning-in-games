%release 2025.0
% !TEX root = main.tex
\documentclass[letterpaper]{article} % DO NOT CHANGE THIS
\usepackage{aaai25}  % DO NOT CHANGE THIS
\usepackage{times}  % DO NOT CHANGE THIS
\usepackage{helvet}  % DO NOT CHANGE THIS
\usepackage{courier}  % DO NOT CHANGE THIS
\usepackage[hyphens]{url}  % DO NOT CHANGE THIS
\usepackage{graphicx} % DO NOT CHANGE THIS
\urlstyle{rm} % DO NOT CHANGE THIS
\def\UrlFont{\rm}  % DO NOT CHANGE THIS
\usepackage{natbib}  % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT
\usepackage{caption} % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT
\frenchspacing  % DO NOT CHANGE THIS
\setlength{\pdfpagewidth}{8.5in}  % DO NOT CHANGE THIS
\setlength{\pdfpageheight}{11in}  % DO NOT CHANGE THIS
%
% These are recommended to typeset algorithms but not required. See the subsubsection on algorithms. Remove them if you don't have algorithms in your paper.
\usepackage{algorithm}
\usepackage{algorithmic}

%
% These are are recommended to typeset listings but not required. See the subsubsection on listing. Remove this block if you don't have listings in your paper.
\usepackage{newfloat}
\usepackage{listings}
\DeclareCaptionStyle{ruled}{labelfont=normalfont,labelsep=colon,strut=off} % DO NOT CHANGE THIS
\lstset{%
	basicstyle={\footnotesize\ttfamily},% footnotesize acceptable for monospace
	numbers=left,numberstyle=\footnotesize,xleftmargin=2em,% show line numbers, remove this entire line if you don't want the numbers.
	aboveskip=0pt,belowskip=0pt,%
	showstringspaces=false,tabsize=2,breaklines=true}
\floatstyle{ruled}
\newfloat{listing}{tb}{lst}{}
\floatname{listing}{Listing}
%
% Keep the \pdfinfo as shown here. There's no need
% for you to add the /Title and /Author tags.
\pdfinfo{
/TemplateVersion (2025.1)
}

% DISALLOWED PACKAGES
% \usepackage{authblk} -- This package is specifically forbidden
% \usepackage{balance} -- This package is specifically forbidden
% \usepackage{color (if used in text)
% \usepackage{CJK} -- This package is specifically forbidden
% \usepackage{float} -- This package is specifically forbidden
% \usepackage{flushend} -- This package is specifically forbidden
% \usepackage{fontenc} -- This package is specifically forbidden
% \usepackage{fullpage} -- This package is specifically forbidden
% \usepackage{geometry} -- This package is specifically forbidden
% \usepackage{grffile} -- This package is specifically forbidden
% \usepackage{hyperref} -- This package is specifically forbidden
% \usepackage{navigator} -- This package is specifically forbidden
% (or any other package that embeds links such as navigator or hyperref)
% \indentfirst} -- This package is specifically forbidden
% \layout} -- This package is specifically forbidden
% \multicol} -- This package is specifically forbidden
% \nameref} -- This package is specifically forbidden
% \usepackage{savetrees} -- This package is specifically forbidden
% \usepackage{setspace} -- This package is specifically forbidden
% \usepackage{stfloats} -- This package is specifically forbidden
% \usepackage{tabu} -- This package is specifically forbidden
% \usepackage{titlesec} -- This package is specifically forbidden
% \usepackage{tocbibind} -- This package is specifically forbidden
% \usepackage{ulem} -- This package is specifically forbidden
% \usepackage{wrapfig} -- This package is specifically forbidden
% DISALLOWED COMMANDS
% \nocopyright -- Your paper will not be published if you use this command
% \addtolength -- This command may not be used
% \balance -- This command may not be used
% \baselinestretch -- Your paper will not be published if you use this command
% \clearpage -- No page breaks of any kind may be used for the final version of your paper
% \columnsep -- This command may not be used
% \newpage -- No page breaks of any kind may be used for the final version of your paper
% \pagebreak -- No page breaks of any kind may be used for the final version of your paperr
% \pagestyle -- This command may not be used
% \tiny -- This is not an acceptable font size.
% \vspace{- -- No negative value may be used in proximity of a caption, figure, table, section, subsection, subsubsection, or reference
% \vskip{- -- No negative value may be used to alter spacing above or below a caption, figure, table, section, subsection, subsubsection, or reference

\setcounter{secnumdepth}{2} %May be changed to 1 or 2 if section numbers are desired.

% The file aaai25.sty is the style file for AAAI Press
% proceedings, working notes, and technical reports.
%

% Title

% Your title must be in mixed case, not sentence case.
% That means all verbs (including short verbs like be, is, using,and go),
% nouns, adverbs, adjectives should be capitalized, including both words in hyphenated terms, while
% articles, conjunctions, and prepositions are lower case unless they
% directly follow a colon or long dash
\title{Planning Approaches for Game Artificial Intelligence: A Survey}
\author{
    %Authors
    % All authors must be in the same font size and format.
    % Written by AAAI Press Staff\textsuperscript{\rm 1}\thanks{With help from the AAAI Publications Committee.}\\
    % AAAI Style Contributions by Samanth Nanda Kumar,\\
    % J. Scott Penberthy,
    % George Ferguson,
    % Hans Guesgen,
    % Francisco Cruz\equalcontrib,
    % Marc Pujol-Gonzalez\equalcontrib
    Samanth Nanda Kumar \\
    Universität Stuttgart \\
    \texttt{st193225@stud.uni-stuttgart.de}
}
% \affiliations{
%     %Afiliations
%     \textsuperscript{\rm 1}Association for the Advancement of Artificial Intelligence\\
%     % If you have multiple authors and multiple affiliations
%     % use superscripts in text and roman font to identify them.
%     % For example,

%     % Sunil Issar\textsuperscript{\rm 2}, 
%     % J. Scott Penberthy\textsuperscript{\rm 3}, 
%     % George Ferguson\textsuperscript{\rm 4},
%     % Hans Guesgen\textsuperscript{\rm 5}
%     % Note that the comma should be placed after the superscript

%     1101 Pennsylvania Ave, NW Suite 300\\
%     Washington, DC 20004 USA\\
%     % email address must be in roman text type, not monospace or sans serif
%     proceedings-questions@aaai.org
% %
% % See more examples next
% }

%Example, Single Author, ->> remove \iffalse,\fi and place them surrounding AAAI title to use it
\iffalse
\title{My Publication Title --- Single Author}
\author {
    Author Name
}
\affiliations{
    Affiliation\\
    Affiliation Line 2\\
    name@example.com
}
\fi

\iffalse
%Example, Multiple Authors, ->> remove \iffalse,\fi and place them surrounding AAAI title to use it
\title{My Publication Title --- Multiple Authors}
\author {
    % Authors
    First Author Name\textsuperscript{\rm 1,\rm 2},
    Second Author Name\textsuperscript{\rm 2},
    Third Author Name\textsuperscript{\rm 1}
}
\affiliations {
    % Affiliations
    \textsuperscript{\rm 1}Affiliation 1\\
    \textsuperscript{\rm 2}Affiliation 2\\
    firstAuthor@affiliation1.com, secondAuthor@affilation2.com, thirdAuthor@affiliation1.com
}
\fi


% REMOVE THIS: bibentry
% This is only needed to show inline citations in the guidelines document. You should not need it and can safely delete it.
\usepackage{bibentry}
% END REMOVE bibentry

\begin{document}

\maketitle

\begin{abstract}
    Artificial intelligence planning has long been explored as a principled approach for generating goal-directed behavior in games. Unlike purely reactive control architectures, planning-based methods explicitly reason about actions, goals, and their consequences, enabling more flexible and adaptive agent behavior. However, the application of planning in games introduces unique challenges, including real-time constraints, highly dynamic environments, and the need for designer control. This paper presents a literature survey of planning approaches applied to games, encompassing symbolic methods such as hierarchical and case-based planning, practical frameworks used in commercial development, and search-based and model-based planning techniques. We analyze representative methods from both academic research and industry practice, compare their strengths and limitations, and discuss open challenges that motivate future research in game AI planning.
\end{abstract}


% Uncomment the following to link to your code, datasets, an extended version or similar.
%
% \begin{links}
%     \link{Code}{https://aaai.org/example/code}
%     \link{Datasets}{https://aaai.org/example/datasets}
%     \link{Extended version}{https://aaai.org/example/extended-version}
% \end{links}

\section{Introduction}

Digital games constitute a challenging and diverse domain for artificial intelligence research. Contemporary games combine large state and action spaces with real-time decision making, stochastic outcomes, and environments that evolve continuously in response to both system dynamics and human player behavior. For these reasons, games have long served not only as experimental testbeds for AI research, but also as application domains in which theoretical methods must be adapted to strict performance, robustness, and design constraints. Within this context, AI planning has emerged as a principled approach for generating goal-directed behavior, providing an alternative to purely reactive or heavily scripted control architectures \cite{hoang2005hierarchical}.

Traditional game AI techniques, such as finite state machines and behavior trees, remain widely used due to their simplicity, predictability, and low computational overhead. However, as game worlds expand in scope and agent responsibilities become more complex, these approaches often struggle to scale. Authoring effort increases substantially, behavior logic becomes difficult to maintain, and agents exhibit limited flexibility when confronted with situations not explicitly anticipated during design. Planning-based approaches seek to address these limitations by explicitly modeling goals, actions, and state transitions, thereby enabling agents to reason about future consequences and revise their behavior dynamically during execution \cite{kelly2007planning}. As a result, planning techniques have been explored across a broad range of game genres, including fast-paced action games as well as large-scale strategy and simulation environments.

Despite their conceptual appeal, planning techniques face significant challenges when applied to games. Classical planning formulations typically assume static environments, offline computation, and complete knowledge of the world state. In contrast, game environments are subject to frequent and unpredictable changes, tight real-time constraints, and strong requirements for designer oversight to ensure believable and controllable agent behavior. These discrepancies have motivated the development of planning approaches that are explicitly tailored to the demands of games, rather than direct applications of classical planners \cite{neufeld2017htn}.

A substantial body of work has focused on symbolic planning methods that allow designers to encode structure and intent directly into agent behavior. Hierarchical Task Network (HTN) planning, for example, decomposes complex behaviors into structured subtasks and has been used to represent reusable strategic knowledge in games \cite{hoang2005hierarchical}. Related symbolic approaches have also explored experience-driven planning through case-based representations, where previously observed solutions are adapted to new situations, particularly in real-time strategy and first-person scenarios \cite{ontanon2007casebased, reuss2006casebased}. These methods emphasize interpretability and designer control, but often rely on substantial domain knowledge and authoring effort.

In parallel, planning techniques have been adopted in commercial game development in more lightweight forms. Goal-Oriented Action Planning (GOAP) was introduced as an alternative to large finite state machines, enabling agents to select actions dynamically based on goals and world-state conditions \cite{orkin2006three}. By decoupling goals from actions and relying on frequent replanning, GOAP demonstrated that planning-based techniques could be deployed effectively in real-time, AAA-scale production environments.

More recently, search-based planning approaches inspired by Monte Carlo Tree Search (MCTS) have gained prominence as a means of handling large decision spaces under uncertainty. Rather than relying on explicit symbolic models, these methods evaluate future action sequences through simulation and statistical estimation \cite{chaslot2008mcts}. Extensions that incorporate abstraction allow search-based planners to scale to complex strategy games \cite{xu2022elastic}. At the same time, advances in model-based reinforcement learning have blurred the boundary between planning and learning, as demonstrated by systems that plan using learned world models rather than hand-crafted representations \cite{schrittwieser2020mastering}.

Taken together, these developments illustrate that planning in games encompasses a broad spectrum of approaches, ranging from symbolic and case-based methods to search-based and model-based techniques. This paper surveys these planning paradigms with the goal of clarifying their underlying assumptions, trade-offs, and suitability for different game contexts.

The remainder of this paper is organized as follows. Section~2 provides background on AI planning and discusses the characteristics of games that motivate specialized planning approaches. Section~3 examines hierarchical planning methods, with a focus on HTN-based representations and their use in encoding strategic knowledge. Section~4 reviews Goal-Oriented Action Planning as a practical planning framework adopted in commercial game development. Section~5 surveys search-based and model-based planning approaches based on Monte Carlo Tree Search and abstraction. Section~6 presents a comparative analysis of these paradigms, highlighting key trade-offs and design considerations. Finally, Section~7 discusses open challenges and future research directions, and Section~8 concludes the paper.

\section{Background: AI Planning in Games}

This section provides the necessary background to situate planning-based approaches within the broader landscape of game AI. Rather than presenting a comprehensive overview of planning techniques, the focus is on clarifying how planning differs from other control paradigms commonly used in games and on identifying the characteristics of game environments that shape the design and application of planning methods.

\subsection{Planning vs.\ Reactive and Learning-Based Game AI}

Historically, game AI has been dominated by reactive control architectures, most notably finite state machines and, more recently, behavior trees. These approaches organize behavior procedurally through explicitly defined states, transitions, or control flows. Their appeal lies in their predictability, low computational overhead, and relative ease of debugging, all of which are important considerations in production environments. As a result, they remain widely used in commercial games.

However, purely reactive systems exhibit limitations as game complexity increases. As the number of states or behaviors grows, authoring and maintaining control logic becomes increasingly difficult. Reactive systems also struggle to generalize beyond situations explicitly anticipated during design, leading to brittle behavior when agents encounter novel circumstances. These limitations have motivated the exploration of alternative approaches that allow agents to reason more explicitly about goals and future consequences.

Planning-based approaches occupy a distinct position within the game AI spectrum. By representing goals, actions, and world state explicitly, planning systems enable agents to construct and revise action sequences at runtime, rather than following fixed control structures. In games, planning is rarely performed as a single offline computation. Instead, planning and execution are typically interleaved, with partial plans generated, adapted, or discarded as the game state evolves. This shift toward online and incremental planning represents a key adaptation of classical planning ideas to interactive environments \cite{neufeld2017htn}.

Learning-based methods have also become increasingly prominent in game AI, particularly in contexts where large amounts of data are available. Learning can complement planning by providing models, heuristics, or policies that support decision making, and recent work has begun to blur the boundary between planning and learning by using learned models within planning processes. At the same time, learning-based approaches often raise concerns related to predictability, interpretability, and designer control. In practice, planning is therefore frequently used alongside reactive and learning-based components, rather than as a replacement, allowing designers to balance autonomy with control.

\begin{figure}[t]
    \centering
    \includegraphics[width=\columnwidth]{figures/section2.png}
    \caption{Conceptual positioning of planning-based approaches within the broader game AI landscape, illustrating the spectrum from reactive control to learning-driven decision making.}
    \label{fig:planning-spectrum}
\end{figure}


\subsection{Characteristics of Games Relevant to Planning}

Games exhibit a number of characteristics that distinguish them from classical planning benchmarks and strongly influence how planning techniques must be applied. One important distinction concerns timing. Many games operate under strict real-time constraints, requiring agents to act within fixed frame budgets, while others adopt turn-based structures that allow more deliberation. Planning methods must therefore accommodate varying time horizons and computational budgets.

Uncertainty is another defining feature of games. Some games are largely deterministic, while others involve stochastic outcomes, hidden information, or adversarial opponents whose actions cannot be predicted in advance. These factors complicate planning by introducing uncertainty into state transitions and action outcomes. As a result, planning techniques in games often rely on frequent replanning, abstraction, or sampling rather than exhaustive reasoning.

Games also vary in terms of agency and interaction. Single-agent settings simplify planning by allowing agents to reason in isolation, whereas multi-agent games introduce additional challenges related to coordination, competition, and interference. In multi-agent environments, planning decisions must account for the actions of other agents, further increasing complexity.

Finally, game environments are typically highly dynamic and only partially observable. World states may change continuously due to physics simulation, non-player characters, and player input. In addition, agents may have incomplete or noisy information about the environment. These properties undermine assumptions of static and fully observable worlds that underlie many classical planning formulations, making direct application impractical \cite{kelly2007planning}.

Taken together, these characteristics explain why planning techniques used in games differ substantially from those developed for classical planning benchmarks. Rather than producing complete plans offline, game-oriented planning approaches emphasize incremental reasoning, adaptability, and close integration with execution. These considerations motivate the specialized planning paradigms examined in the following sections.


\section{Hierarchical Planning for Games}

The characteristics of games discussed in the previous section motivate planning approaches that can balance adaptability with designer control. Hierarchical planning has emerged as a particularly influential paradigm in this context, as it allows reasoning at multiple levels of abstraction while constraining agent behavior in ways that remain compatible with game design requirements. This section examines Hierarchical Task Network (HTN) planning as a representative hierarchical approach, and situates it alongside related knowledge-driven planning methods that emphasize structure, reuse, and strategic control.

\begin{figure}[t]
    \centering
    \includegraphics[width=\columnwidth]{figures/section3.png}
    \caption{Example Hierarchical Task Network for a guard NPC securing an objective in a game environment. High-level tasks are decomposed into alternative methods and primitive actions, with execution guided by preconditions and evolving world state.}
    \label{fig:htn-network}
\end{figure}

\subsection{Hierarchical Task Networks}

Hierarchical Task Network planning differs from classical goal-based planning by formulating problems in terms of tasks rather than explicit goal states. In an HTN, high-level tasks represent abstract objectives, which are decomposed into subtasks through the application of methods. This process continues until primitive actions are produced that can be executed directly in the game world. The hierarchy implicitly encodes control knowledge, guiding the planner toward behavior sequences that are meaningful within the domain.

For games, this task-centered formulation offers several advantages. By embedding domain knowledge into task decompositions, designers can restrict the space of admissible plans, ensuring that generated behavior aligns with intended gameplay. At the same time, the hierarchical structure supports reasoning at an appropriate level of abstraction, allowing agents to make strategic decisions without committing prematurely to low-level actions. As a result, HTNs are well suited to domains that require long-term planning, coordination, or narrative coherence.

\subsection{Encoding Strategic Knowledge with HTNs}

Early work by Hoang et al.\ demonstrated how HTN representations could be used to encode strategic knowledge for game agents in a reusable and modular form \cite{hoang2005hierarchical}. In their approach, high-level strategies were captured as abstract tasks, while methods specified alternative ways of realizing these strategies under different conditions. This structure allowed agents to reuse previously generated plans and to adapt them to new situations without replanning from scratch.

Encoding strategy hierarchically offers clear benefits for scalability and maintainability. By decomposing behavior into modular components, designers can modify or extend specific parts of the hierarchy without redesigning the entire planning model. In comparison to flat planning representations, this approach reduces combinatorial complexity and supports more consistent strategic behavior across gameplay scenarios.

However, these benefits come with trade-offs. The effectiveness of HTN planning depends heavily on the quality and completeness of the encoded domain knowledge. Authoring task hierarchies requires substantial expertise and effort, and omissions or overly restrictive decompositions can limit behavioral diversity. These limitations highlight an inherent tension between control and flexibility that recurs across hierarchical planning approaches.

\subsection{Case-Based Planning as Knowledge Reuse}

Closely related to hierarchical planning, case-based planning approaches emphasize the reuse of previously observed solutions as a means of guiding future behavior. Rather than constructing plans entirely from scratch, agents retrieve and adapt stored cases that represent successful action sequences in similar situations. In games, this approach provides a natural mechanism for encoding experience-driven strategic knowledge while maintaining strong designer control.

Case-based planning has been applied in both first-person and real-time strategy games, where agents must operate under real-time constraints and respond to recurring tactical situations \cite{reuss2006casebased,ontanon2007casebased}. By leveraging past solutions, these systems reduce online planning effort and support rapid decision making. From a representational perspective, case-based planning occupies a middle ground between explicit hierarchical decomposition and reactive control, relying on structured knowledge without requiring full task hierarchies.

At the same time, case-based approaches share several limitations with HTNs. Their effectiveness depends on the quality, coverage, and maintenance of the case library, and adapting cases to novel situations can introduce complexity. As with HTNs, authoring and curating domain knowledge remains a significant challenge, particularly as game mechanics evolve.

\subsection{Hierarchical Planning under Game Constraints}

While early hierarchical approaches emphasized strategic encoding, subsequent work addressed the practical constraints imposed by real-time game environments. Kelly et al.\ investigated how HTN planning could be integrated into video games where planning and execution must occur under tight computational budgets \cite{kelly2007planning}. Rather than generating complete plans offline, their approach emphasized incremental planning, allowing agents to interleave planning with action execution.

This shift from offline to online planning marked an important adaptation of hierarchical planning to games. By monitoring execution and revising plans when necessary, agents could respond to unexpected changes in the game state without discarding hierarchical structure altogether. Compared to static planning approaches, this enabled greater responsiveness while preserving the benefits of strategic decomposition.

At the same time, online hierarchical planning introduces additional complexity. Monitoring plan validity, deciding when to replan, and limiting computational overhead all require careful design choices. These challenges underscore the difficulty of applying structured planning in environments where real-time responsiveness is essential.

\subsection{Hierarchical Planning in Highly Dynamic Games}

The challenges of dynamic and fast-paced game environments were further explored by Neufeld et al.\ in the \emph{HTN Fighter} system \cite{neufeld2017htn}. Designed for combat scenarios with frequent and unpredictable state changes, the system relied on frequent replanning and shallow task decompositions to maintain responsiveness. Rather than pursuing optimal plans, the focus shifted toward producing timely and robust behavior.

This work highlights a key trade-off in hierarchical planning for games. Deep hierarchies and extensive deliberation support strategic optimality but are poorly suited to highly dynamic environments. Conversely, limiting decomposition depth and prioritizing reactive responses improves responsiveness at the cost of long-term optimality. The design of \emph{HTN Fighter} illustrates how hierarchical planning approaches can be adapted along this spectrum, depending on the demands of the game.

Across these studies, a consistent pattern emerges. Hierarchical and knowledge-driven planning approaches offer strong designer control and support strategic reasoning, but their effectiveness depends on careful adaptation to game-specific constraints. Static environments favor deeper hierarchies and offline reasoning, while dynamic environments require online planning, frequent replanning, and reduced structural commitment. These trade-offs motivate the consideration of less structured planning paradigms that emphasize flexibility and reactivity, which are examined in the following section.


\section{Goal-Oriented Action Planning in Practice}

While hierarchical and knowledge-driven planning approaches emphasize structure, reuse, and explicit strategic guidance, their authoring complexity and reliance on detailed domain modeling can limit their applicability in some game contexts. In response to these challenges, Goal-Oriented Action Planning (GOAP) emerged as a more lightweight planning framework designed to manage behavioral complexity without relying on deep hierarchical representations or extensive knowledge bases. This section examines GOAP as a practical alternative to traditional reactive systems and situates its adoption within the constraints of commercial game development.

\subsection{From Finite State Machines to Declarative Planning}

The development of GOAP was motivated in large part by the limitations of finite state machines (FSMs) as game AI systems grew in scale. FSM-based architectures encode behavior procedurally through explicit states and transitions, which become increasingly difficult to author and maintain as the number of behaviors increases. As transitions proliferate, the resulting control logic becomes brittle and hard to extend, particularly when new behaviors must interact with existing ones.

GOAP addresses this problem by shifting from procedural control flow to a declarative representation of behavior. Rather than specifying how agents transition between states, designers define actions in terms of preconditions and effects, along with goals that describe desired world-state properties. At runtime, the planner selects and sequences actions based on the current state and the active goal. This separation of goals and actions reduces coupling between behaviors and allows agents to respond flexibly to changing circumstances without requiring explicit transition logic.

In contrast to hierarchical and case-based planning approaches, GOAP relies on a flat action representation rather than structured task decompositions or reusable plan fragments. This design choice simplifies authoring and supports rapid adaptation, but it also limits the planner’s ability to reason explicitly about long-term strategy. As a result, GOAP is particularly well suited to tactical decision making in dynamic environments where responsiveness is prioritized over strategic depth.

\subsection{GOAP in Commercial Games}

A prominent application of GOAP was presented by Orkin in the context of the commercial first-person shooter \emph{F.E.A.R.} \cite{orkin2006three}. In this setting, GOAP was introduced to replace large FSM-based systems that had become difficult to scale and maintain within a AAA production pipeline. The planner used an A*-based search over actions, treating action costs as a heuristic measure of desirability.

By decoupling goals from actions, the system allowed non-player characters to exhibit context-sensitive behavior without requiring designers to script all possible scenarios explicitly. Agents could select actions such as seeking cover, flanking enemies, or coordinating with allies based on the current state of the environment and their active goals. Frequent replanning enabled agents to respond to changes in real time, producing behavior that appeared adaptive and coherent from the player’s perspective.

The significance of this approach lies not only in its technical design, but also in its successful deployment in a commercial setting. GOAP demonstrated that planning-based techniques could be integrated into real-time games under strict performance constraints, while remaining accessible to designers and compatible with production workflows. This helped establish GOAP as a practical planning framework beyond academic prototypes.

\subsection{Strengths and Limitations of GOAP}

GOAP offers several strengths that have contributed to its adoption in practice. Its declarative representation improves modularity and scalability compared to FSM-based systems, allowing new actions and goals to be introduced with minimal changes to existing behavior logic. Frequent replanning increases robustness in dynamic environments, and the explicit representation of goals and actions supports debugging and tuning by designers.

At the same time, GOAP exhibits limitations that constrain its applicability. As the number of available actions grows, the flat action space can lead to increased planning costs, particularly in scenarios that require frequent replanning. In addition, the absence of hierarchical structure or explicit knowledge reuse makes it difficult to encode long-term strategy or high-level narrative constraints. Compared to more structured planning approaches, GOAP offers less direct support for strategic reasoning and designer-authored abstraction.

In practice, these limitations are often mitigated through the use of heuristics, goal prioritization schemes, or domain-specific constraints. Nevertheless, they highlight a recurring trade-off between flexibility and structure that distinguishes GOAP from both hierarchical and case-based planning. These considerations motivate the exploration of planning paradigms that further relax symbolic structure in favor of scalability and generality, which are examined in the following section.


\section{Search-Based and Model-Based Planning with State Abstraction}

The planning approaches discussed so far rely on explicit symbolic representations of goals, actions, and domain knowledge. While such representations support interpretability and designer control, they can be difficult to scale to environments with large state spaces or complex dynamics. Search-based planning offers an alternative perspective by framing decision making as an online process of exploration and evaluation, rather than symbolic reasoning over predefined models. This section examines search-based and model-based planning approaches for games, with a particular focus on Monte Carlo Tree Search and the role of abstraction in enabling scalability.

\subsection{Monte Carlo Tree Search for Games}

Monte Carlo Tree Search (MCTS) has emerged as a foundational framework for decision making and planning in games, particularly in domains characterized by uncertainty, adversarial interaction, and large branching factors \cite{chaslot2008mcts}. Unlike symbolic planners, which construct plans by reasoning over explicit action models and goal descriptions, MCTS incrementally builds a search tree through simulated action sequences and statistical evaluation of outcomes. Decisions are guided by a balance between exploration of new possibilities and exploitation of previously successful actions.

From a planning perspective, MCTS can be understood as an online planning method that evaluates future trajectories rather than producing explicit, reusable plans. It does not require a complete symbolic model of the domain and can operate with a generative model of state transitions. This property makes MCTS attractive in game settings where modeling all relevant dynamics explicitly is impractical. At the same time, the absence of explicit goals and symbolic structure distinguishes MCTS from approaches such as HTNs and GOAP, shifting emphasis toward evaluation, simulation, and statistical estimation.

\subsection{State Abstraction in Search-Based Planning}

A central challenge for search-based planning in games is the combinatorial explosion of state and action spaces. As games increase in complexity, exhaustive search quickly becomes infeasible, particularly under real-time constraints. State abstraction addresses this challenge by reducing the effective complexity of the search space, either by grouping similar states or by reasoning at higher levels of granularity.

Abstraction can be introduced in different ways. Domain-dependent abstractions rely on hand-crafted knowledge about the game structure, allowing planners to ignore irrelevant details and focus on strategically meaningful features. Domain-independent abstractions aim to reduce complexity without relying on extensive prior knowledge, often through generic feature selection or sampling strategies. While domain-dependent abstraction can be highly effective, it reintroduces authoring effort and limits generality. Domain-independent approaches offer greater flexibility but may sacrifice precision or interpretability.

In the context of planning, abstraction enables agents to trade accuracy for responsiveness, allowing timely decisions even when exact reasoning is computationally prohibitive. This trade-off is particularly important in large strategy games and simulations, where planning horizons are long and the state space is vast.

\subsection{Elastic Monte Carlo Tree Search}

Xu et al.\ proposed Elastic Monte Carlo Tree Search as an approach that integrates abstraction directly into the search process \cite{xu2022elastic}. Rather than relying on a fixed abstraction scheme, their method dynamically adjusts abstraction granularity based on the available computational budget and properties of the current game state. When resources permit, the planner reasons at a finer level of detail; under tighter constraints, it operates on more abstract representations.

This dynamic adjustment allows the planner to balance strategic reasoning and real-time responsiveness more effectively than static abstraction schemes. In large strategy games, elastic abstraction enables agents to consider long-term consequences without committing to prohibitively expensive fine-grained search. Compared to symbolic planning approaches, Elastic MCTS reduces reliance on explicit domain modeling, while still supporting strategic decision making through adaptive abstraction.

\subsection{Model-Based Planning with Learned Dynamics}

Recent work has further extended search-based planning by incorporating learned models of environment dynamics. Rather than relying on hand-crafted transition models or simulators, these approaches learn predictive models from data and use them to guide planning through simulation. This paradigm blurs the traditional boundary between planning and learning, as decision making depends on both search and learned representations.

Schrittwieser et al.\ demonstrated the effectiveness of this approach in a range of games by combining Monte Carlo Tree Search with learned world models \cite{schrittwieser2020mastering}. In this setting, planning is performed in a latent state space learned from experience, allowing agents to reason about future outcomes without explicit symbolic descriptions of actions or states. This significantly reduces manual modeling effort and enables scalability to complex domains.

While model-based planning with learned dynamics offers impressive generality, it also introduces new challenges. Learned models can be difficult to interpret, and errors in prediction may lead to brittle behavior. Moreover, designer control is largely indirect, mediated through training objectives rather than explicit behavioral constraints. These properties contrast sharply with symbolic planning approaches, highlighting a fundamental trade-off between generality and control.

\subsection{Discussion: Symbolic, Search-Based, and Model-Based Planning}

Comparing symbolic, search-based, and model-based planning approaches reveals complementary strengths and limitations. Symbolic planners such as HTNs, GOAP, and case-based methods emphasize interpretability, designer control, and explicit representation of goals and structure. These properties support alignment with design intent but require substantial authoring effort and domain expertise.

Search-based planners emphasize scalability and generality, relying on simulation and evaluation rather than explicit symbolic models. Model-based planning with learned dynamics further reduces manual modeling requirements, enabling planning in domains where explicit representations are impractical. However, these gains come at the cost of reduced transparency and limited direct control over agent behavior.

Together, these paradigms illustrate that planning in games cannot be addressed by a single dominant approach. Instead, different techniques occupy distinct points in the design space defined by interpretability, scalability, authoring effort, and computational cost. Understanding these trade-offs provides essential context for the comparative analysis presented in the following section.


\section{Comparative Analysis and Synthesis}

The planning approaches discussed in the previous sections span a broad spectrum, ranging from symbolic and knowledge-driven methods to search-based and model-based techniques. These paradigms differ fundamentally in how knowledge is represented, how decisions are generated, and how control is distributed between designers and autonomous agents. In this section, we compare these approaches along dimensions that are particularly relevant to game AI and synthesize the trade-offs that emerge in practice.

\begin{figure}[t]
    \centering
    \includegraphics[width=\columnwidth]{figures/section6.png}
    \caption{Conceptual comparison of planning paradigms in games along a spectrum from explicit, designer-controlled representations to flexible, autonomous decision making.}
    \label{fig:htn-network}
\end{figure}

\subsection{Representation and Knowledge Encoding}

Symbolic planning approaches rely on explicit representations of domain knowledge. HTN-based methods encode strategic intent and behavioral structure directly through hierarchical task decompositions, providing strong guidance over agent behavior and supporting long-term coordination. GOAP adopts a flatter symbolic representation in which actions and goals are specified independently, reducing structural complexity while retaining goal-directed reasoning. Case-based planning similarly relies on explicit knowledge, but emphasizes the reuse of stored experience rather than predefined hierarchies.

Search-based planning methods avoid explicit symbolic representations and instead depend on simulation, evaluation functions, and abstraction to guide decision making. Model-based planning with learned dynamics further reduces reliance on hand-crafted representations by learning predictive models from data. While these approaches significantly reduce manual modeling effort, they also make resulting behavior harder to interpret and constrain from a design perspective.

\subsection{Reactivity and Adaptability}

Reactivity is a central strength of GOAP and search-based approaches. In GOAP systems, frequent replanning enables agents to respond quickly to changes in the environment, which is particularly valuable in dynamic and tactical scenarios. Search-based planners achieve adaptability through online simulation and selection, naturally accommodating uncertainty and adversarial dynamics. Model-based planning extends this adaptability by enabling search over learned representations, allowing agents to generalize across states without explicit symbolic descriptions.

HTN-based planners can also adapt at runtime, but typically within the bounds imposed by their hierarchical structure. While this constraint improves predictability and alignment with design intent, it may limit responsiveness in rapidly changing environments unless replanning mechanisms are carefully designed.

\subsection{Computational Considerations}

Real-time performance places strict limits on planning complexity in games. HTN planners address this challenge by constraining the search space through task decompositions, enabling tractable planning even in domains with rich behavior sets. GOAP systems trade structural guidance for simplicity, which can lead to increased computational costs as the action space grows, particularly when replanning occurs frequently.

Search-based planners face the greatest computational demands due to large state and action spaces, but abstraction and sampling techniques allow them to scale by accepting approximate solutions in exchange for timely decisions. Model-based planning with learned dynamics further shifts computational cost toward training, reducing online modeling requirements at the expense of increased system complexity and potential instability when learned models are inaccurate.

\subsection{Designer Control and Authoring Effort}

The degree of designer control varies substantially across planning paradigms. HTNs provide the strongest control, as designers explicitly define permissible behaviors and strategies through task hierarchies. Case-based planning similarly supports control through curated experience, although behavior depends on the coverage and quality of the case library. GOAP offers a more balanced approach, allowing designers to specify actions and goals without prescribing complete behavior sequences.

Search-based and model-based planning provide the least direct designer control, as behavior emerges from evaluation, simulation, and learned representations. In these approaches, authoring effort shifts away from defining explicit behavior toward designing evaluation functions, abstractions, or training objectives. This shift improves scalability and generality, but complicates debugging and alignment with narrative or stylistic constraints.

\subsection{Summary of Trade-Offs}

Table~\ref{tab:comparison} summarizes the key characteristics of the planning paradigms discussed in this survey.

\begin{table*}[t]
    \centering
    \small
    \begin{tabular}{lcccc}
        \hline
        \textbf{Dimension} & \textbf{HTN}           & \textbf{GOAP}  & \textbf{Search-Based} & \textbf{Model-Based} \\
        \hline
        Knowledge Encoding & Hierarchical, explicit & Symbolic, flat & Implicit, evaluative  & Learned, implicit    \\
        Reactivity         & Moderate               & High           & High                  & High                 \\
        Long-Term Strategy & Strong                 & Limited        & Emergent              & Emergent             \\
        Designer Control   & High                   & Medium         & Low                   & Very low             \\
        Authoring Effort   & High                   & Medium         & Low                   & Low (design-time)    \\
        Scalability        & Moderate               & Moderate       & High (abstraction)    & Very high            \\
        Interpretability   & High                   & Medium         & Low                   & Low                  \\
        \hline
    \end{tabular}
    \caption{Comparison of planning paradigms in games across key dimensions.}
    \label{tab:comparison}
\end{table*}

Overall, no single planning paradigm dominates across all criteria. Hierarchical and case-based planning excel in domains that demand strategic consistency, coordination, and strong designer control. GOAP offers a pragmatic compromise between structure and flexibility, making it attractive for real-time and tactical gameplay. Search-based and model-based planning approaches scale to large and complex domains where explicit modeling is impractical, but they trade interpretability and direct control for generality and adaptability. These differences underscore the importance of selecting planning techniques based on the specific requirements of the game domain and motivate continued exploration of hybrid and adaptive approaches.


\section{Open Challenges and Research Directions}

Although planning techniques have been applied successfully across a wide range of game genres, several open challenges remain. These challenges arise not only from technical limitations, but also from the broader design, production, and interaction constraints that distinguish games from more traditional planning domains. Addressing them is essential for extending the practical impact of planning-based game AI.

A persistent challenge concerns the effort required to author and maintain planning models. Hierarchical and case-based approaches, in particular, depend on carefully constructed task decompositions or curated experience libraries, while GOAP systems rely on well-designed action sets and goal specifications. These representations provide valuable structure and designer control, but they are time-consuming to develop and sensitive to modeling errors. As games evolve during development, maintaining alignment between planning models and game mechanics can become increasingly burdensome. Reducing authoring cost through improved tooling, higher-level abstractions, or partial automation remains an important research direction.

Closely related is the challenge of integrating planning with learning-based methods. Most planning systems used in games rely on hand-crafted models, heuristics, or abstractions, which supports predictability and interpretability but limits adaptability. Learning-based techniques offer the potential to acquire models, evaluation functions, or abstractions from data, as demonstrated by recent model-based planning approaches. However, combining learning with planning raises concerns about stability, transparency, and designer trust, particularly when learned representations are difficult to interpret. Balancing adaptability with control remains an open problem, especially in production environments where predictable behavior is critical.

Evaluation and benchmarking present additional difficulties. Unlike classical planning benchmarks, games vary widely in mechanics, objectives, and success criteria. Agent behavior is often judged not only by effectiveness, but also by qualities such as believability, behavioral diversity, and player experience. These factors complicate direct comparison of planning approaches and limit the usefulness of purely technical metrics. Developing evaluation methodologies that capture both performance and design-oriented criteria would enable more systematic assessment of planning techniques in games.

Scalability under real-time constraints continues to be a central concern as games grow in complexity. While abstraction, sampling, and incremental planning have enabled planning in increasingly large state spaces, guaranteeing timely responses remains challenging, particularly in multi-agent settings where coordination and interaction further increase computational demands. Approaches that adapt planning effort dynamically based on available resources and gameplay context represent a promising direction for addressing these constraints.

Finally, the relationship between planning systems and game design raises broader questions about agency and control. Designers must balance autonomous agent behavior with narrative structure, pacing, and aesthetic intent. Planning systems that are too restrictive risk producing repetitive or predictable behavior, while overly flexible systems may undermine narrative coherence or gameplay balance. Understanding how planning techniques can better support designer intent, rather than merely replacing scripted control, remains an important challenge.

Taken together, these challenges suggest that the future of planning in games is unlikely to be defined by a single dominant paradigm. Instead, progress is likely to emerge from hybrid systems that combine structured symbolic representations, experience-driven reuse, search-based decision making, and learning-based adaptation. Exploring how these components can be integrated in a principled and practical manner remains a central research direction for planning-based game AI.


\section{Conclusion}

This paper has surveyed planning-based approaches for game AI, examining a range of paradigms that have been developed to address the unique demands of interactive game environments. Rather than treating planning as a single, uniform technique, the literature reveals a spectrum of approaches shaped by real-time constraints, dynamic state evolution, uncertainty, and the need to balance autonomous decision making with designer control.

Hierarchical and knowledge-driven planning methods, including Hierarchical Task Networks and case-based planning, provide strong structure and interpretability, making them well suited to domains that require long-term strategy, coordination, and explicit design guidance. Goal-Oriented Action Planning offers a more lightweight symbolic alternative, trading strategic structure for flexibility and responsiveness, and has demonstrated its practicality in commercial game development. Search-based and model-based planning approaches, particularly those built on Monte Carlo Tree Search, emphasize scalability and generality, enabling decision making in large and uncertain state spaces while reducing reliance on hand-crafted domain models.

The comparative analysis highlights that no single planning paradigm is universally optimal across all game scenarios. Instead, the suitability of a given approach depends on factors such as computational constraints, the desired level of designer involvement, and the nature of the gameplay experience. In practice, effective game AI systems often combine elements from multiple paradigms, integrating planning with reactive control, heuristics, abstraction, and, increasingly, learning-based components.

Overall, planning remains a central and evolving component of game AI research. While substantial progress has been made in adapting planning techniques to interactive environments, important challenges related to authoring effort, scalability, evaluation, and integration with learning persist. Addressing these challenges will be essential for advancing the role of planning in future games and for narrowing the gap between academic research and practical game development.


\bibliographystyle{aaai25}
\bibliography{aaai25}

\end{document}
