%release 2025.0
% !TEX root = main.tex
\documentclass[letterpaper]{article} % DO NOT CHANGE THIS
\usepackage{aaai25}  % DO NOT CHANGE THIS
\usepackage{times}  % DO NOT CHANGE THIS
\usepackage{helvet}  % DO NOT CHANGE THIS
\usepackage{courier}  % DO NOT CHANGE THIS
\usepackage[hyphens]{url}  % DO NOT CHANGE THIS
\usepackage{graphicx} % DO NOT CHANGE THIS
\urlstyle{rm} % DO NOT CHANGE THIS
\def\UrlFont{\rm}  % DO NOT CHANGE THIS
\usepackage{natbib}  % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT
\usepackage{caption} % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT
\frenchspacing  % DO NOT CHANGE THIS
\setlength{\pdfpagewidth}{8.5in}  % DO NOT CHANGE THIS
\setlength{\pdfpageheight}{11in}  % DO NOT CHANGE THIS
%
% These are recommended to typeset algorithms but not required. See the subsubsection on algorithms. Remove them if you don't have algorithms in your paper.
\usepackage{algorithm}
\usepackage{algorithmic}

%
% These are are recommended to typeset listings but not required. See the subsubsection on listing. Remove this block if you don't have listings in your paper.
\usepackage{newfloat}
\usepackage{listings}
\DeclareCaptionStyle{ruled}{labelfont=normalfont,labelsep=colon,strut=off} % DO NOT CHANGE THIS
\lstset{%
	basicstyle={\footnotesize\ttfamily},% footnotesize acceptable for monospace
	numbers=left,numberstyle=\footnotesize,xleftmargin=2em,% show line numbers, remove this entire line if you don't want the numbers.
	aboveskip=0pt,belowskip=0pt,%
	showstringspaces=false,tabsize=2,breaklines=true}
\floatstyle{ruled}
\newfloat{listing}{tb}{lst}{}
\floatname{listing}{Listing}
%
% Keep the \pdfinfo as shown here. There's no need
% for you to add the /Title and /Author tags.
\pdfinfo{
/TemplateVersion (2025.1)
}

% DISALLOWED PACKAGES
% \usepackage{authblk} -- This package is specifically forbidden
% \usepackage{balance} -- This package is specifically forbidden
% \usepackage{color (if used in text)
% \usepackage{CJK} -- This package is specifically forbidden
% \usepackage{float} -- This package is specifically forbidden
% \usepackage{flushend} -- This package is specifically forbidden
% \usepackage{fontenc} -- This package is specifically forbidden
% \usepackage{fullpage} -- This package is specifically forbidden
% \usepackage{geometry} -- This package is specifically forbidden
% \usepackage{grffile} -- This package is specifically forbidden
% \usepackage{hyperref} -- This package is specifically forbidden
% \usepackage{navigator} -- This package is specifically forbidden
% (or any other package that embeds links such as navigator or hyperref)
% \indentfirst} -- This package is specifically forbidden
% \layout} -- This package is specifically forbidden
% \multicol} -- This package is specifically forbidden
% \nameref} -- This package is specifically forbidden
% \usepackage{savetrees} -- This package is specifically forbidden
% \usepackage{setspace} -- This package is specifically forbidden
% \usepackage{stfloats} -- This package is specifically forbidden
% \usepackage{tabu} -- This package is specifically forbidden
% \usepackage{titlesec} -- This package is specifically forbidden
% \usepackage{tocbibind} -- This package is specifically forbidden
% \usepackage{ulem} -- This package is specifically forbidden
% \usepackage{wrapfig} -- This package is specifically forbidden
% DISALLOWED COMMANDS
% \nocopyright -- Your paper will not be published if you use this command
% \addtolength -- This command may not be used
% \balance -- This command may not be used
% \baselinestretch -- Your paper will not be published if you use this command
% \clearpage -- No page breaks of any kind may be used for the final version of your paper
% \columnsep -- This command may not be used
% \newpage -- No page breaks of any kind may be used for the final version of your paper
% \pagebreak -- No page breaks of any kind may be used for the final version of your paperr
% \pagestyle -- This command may not be used
% \tiny -- This is not an acceptable font size.
% \vspace{- -- No negative value may be used in proximity of a caption, figure, table, section, subsection, subsubsection, or reference
% \vskip{- -- No negative value may be used to alter spacing above or below a caption, figure, table, section, subsection, subsubsection, or reference

\setcounter{secnumdepth}{2} %May be changed to 1 or 2 if section numbers are desired.

% The file aaai25.sty is the style file for AAAI Press
% proceedings, working notes, and technical reports.
%

% Title

% Your title must be in mixed case, not sentence case.
% That means all verbs (including short verbs like be, is, using,and go),
% nouns, adverbs, adjectives should be capitalized, including both words in hyphenated terms, while
% articles, conjunctions, and prepositions are lower case unless they
% directly follow a colon or long dash
\title{Planning Approaches for Game Artificial Intelligence: A Survey}
\author{
    %Authors
    % All authors must be in the same font size and format.
    % Written by AAAI Press Staff\textsuperscript{\rm 1}\thanks{With help from the AAAI Publications Committee.}\\
    % AAAI Style Contributions by Samanth Nanda Kumar,\\
    % J. Scott Penberthy,
    % George Ferguson,
    % Hans Guesgen,
    % Francisco Cruz\equalcontrib,
    % Marc Pujol-Gonzalez\equalcontrib
    Samanth Nanda Kumar \\
    Universität Stuttgart \\
    \texttt{st193225@stud.uni-stuttgart.de}
}
% \affiliations{
%     %Afiliations
%     \textsuperscript{\rm 1}Association for the Advancement of Artificial Intelligence\\
%     % If you have multiple authors and multiple affiliations
%     % use superscripts in text and roman font to identify them.
%     % For example,

%     % Sunil Issar\textsuperscript{\rm 2}, 
%     % J. Scott Penberthy\textsuperscript{\rm 3}, 
%     % George Ferguson\textsuperscript{\rm 4},
%     % Hans Guesgen\textsuperscript{\rm 5}
%     % Note that the comma should be placed after the superscript

%     1101 Pennsylvania Ave, NW Suite 300\\
%     Washington, DC 20004 USA\\
%     % email address must be in roman text type, not monospace or sans serif
%     proceedings-questions@aaai.org
% %
% % See more examples next
% }

%Example, Single Author, ->> remove \iffalse,\fi and place them surrounding AAAI title to use it
\iffalse
\title{My Publication Title --- Single Author}
\author {
    Author Name
}
\affiliations{
    Affiliation\\
    Affiliation Line 2\\
    name@example.com
}
\fi

\iffalse
%Example, Multiple Authors, ->> remove \iffalse,\fi and place them surrounding AAAI title to use it
\title{My Publication Title --- Multiple Authors}
\author {
    % Authors
    First Author Name\textsuperscript{\rm 1,\rm 2},
    Second Author Name\textsuperscript{\rm 2},
    Third Author Name\textsuperscript{\rm 1}
}
\affiliations {
    % Affiliations
    \textsuperscript{\rm 1}Affiliation 1\\
    \textsuperscript{\rm 2}Affiliation 2\\
    firstAuthor@affiliation1.com, secondAuthor@affilation2.com, thirdAuthor@affiliation1.com
}
\fi


% REMOVE THIS: bibentry
% This is only needed to show inline citations in the guidelines document. You should not need it and can safely delete it.
\usepackage{bibentry}
% END REMOVE bibentry

\begin{document}

\maketitle

\begin{abstract}
    Artificial intelligence planning has long been explored as a principled approach for generating goal-directed behavior in games. Unlike purely reactive control architectures, planning-based methods explicitly reason about actions, goals, and their consequences, enabling more flexible and adaptive agent behavior. However, the application of planning in games introduces unique challenges, including real-time constraints, highly dynamic environments, and the need for designer control. This paper presents a literature survey of planning approaches applied to games, encompassing symbolic methods such as hierarchical and case-based planning, practical frameworks used in commercial development, and search-based and model-based planning techniques. We analyze representative methods from both academic research and industry practice, compare their strengths and limitations, and discuss open challenges that motivate future research in game AI planning.
\end{abstract}


% Uncomment the following to link to your code, datasets, an extended version or similar.
%
% \begin{links}
%     \link{Code}{https://aaai.org/example/code}
%     \link{Datasets}{https://aaai.org/example/datasets}
%     \link{Extended version}{https://aaai.org/example/extended-version}
% \end{links}

\section{Introduction}

Digital games constitute a challenging and diverse domain for artificial intelligence research. Contemporary games combine large state and action spaces with real-time decision making, stochastic outcomes, and environments that evolve continuously in response to both system dynamics and human player behavior. For these reasons, games have long served not only as experimental testbeds for AI research, but also as application domains in which theoretical methods must be adapted to strict performance, robustness, and design constraints. Unlike many traditional AI domains, game AI systems are further shaped by requirements of believability, player experience, and designer intent, which place unique demands on decision-making architectures \cite{laird2001human,yannakakis2018games}.

Within this context, AI planning has emerged as a principled approach for generating goal-directed behavior, offering an alternative to purely reactive or heavily scripted control architectures \cite{hoang2005hierarchical}. Traditional game AI techniques, such as finite state machines and behavior trees, remain widely used due to their simplicity, predictability, and low computational overhead. However, as game worlds expand in scope and agent responsibilities increase, these approaches often struggle to scale. Authoring effort grows rapidly, behavior logic becomes difficult to maintain, and agents exhibit limited flexibility when confronted with situations not explicitly anticipated during design.

Planning-based approaches seek to address these limitations by explicitly modeling goals, actions, and state transitions, enabling agents to reason about future consequences and revise their behavior dynamically during execution \cite{kelly2007planning}. Rather than executing fixed control flows, planning allows behavior to be constructed online in response to changing conditions. At the same time, planning in games departs significantly from classical formulations, which typically assume static environments, offline computation, and complete knowledge of the world state. In contrast, game environments are highly dynamic, time-constrained, and demand strong designer oversight to ensure controllable and interpretable agent behavior. These discrepancies have motivated the development of planning approaches explicitly tailored to the demands of games \cite{neufeld2017htn}.

A substantial body of work has focused on symbolic planning methods that allow designers to encode structure and intent directly into agent behavior. Hierarchical Task Network (HTN) planning decomposes complex behaviors into structured subtasks and has been used to represent reusable strategic knowledge in games \cite{hoang2005hierarchical}. Related symbolic approaches explore experience-driven planning through case-based representations, in which previously observed solutions are adapted to new situations, particularly in real-time strategy and first-person scenarios \cite{ontanon2007casebased,reuss2006casebased}. These methods emphasize interpretability and designer control, but typically rely on extensive domain knowledge and careful authoring.

In parallel, commercial game development has adopted more lightweight decision-making architectures that occupy a middle ground between symbolic planning and purely reactive control. Goal-Oriented Action Planning (GOAP) enables agents to select actions dynamically based on goals and world-state conditions, reducing authoring complexity while retaining goal-directed behavior \cite{orkin2006three}. Closely related, utility-based decision systems evaluate actions using continuous desirability or need functions, offering a flexible and computationally efficient alternative that has seen widespread adoption in simulation and life-simulation games \cite{mark2009behavioral}. These approaches trade explicit symbolic structure for scalability and robustness in dynamic environments.

Search-based planning methods provide a complementary perspective by framing decision making as online exploration rather than symbolic reasoning. Monte Carlo Tree Search (MCTS) has become a dominant technique for planning under uncertainty in games by evaluating future action sequences through simulation and statistical estimation \cite{chaslot2008mcts}. Extensions incorporating abstraction allow search-based planners to scale to large strategy games \cite{xu2022elastic}. Advances in model-based reinforcement learning have further blurred the boundary between planning and learning, as demonstrated by systems that plan using learned world models instead of hand-crafted dynamics \cite{schrittwieser2020mastering}.

More recently, large language models (LLMs) have introduced a qualitatively different approach to planning in games and interactive environments. Rather than operating over predefined symbolic operators or search trees, LLM-based agents perform planning at a semantic level, using natural language to represent goals, actions, memories, and environmental affordances. Systems such as \emph{Voyager} demonstrate how LLMs can function as high-level planners for open-ended embodied tasks by generating, revising, and reusing action plans expressed in language \cite{wang2023voyager}. Similarly, generative agent architectures combine memory, reflection, and language-driven planning to produce coherent long-term behavior in simulated environments \cite{park2023generative}. These approaches emphasize abstraction and generalization, while raising new challenges related to reliability, latency, and designer control.

Taken together, these developments illustrate that planning in games now encompasses a broad spectrum of paradigms, ranging from symbolic and case-based methods to utility-driven, search-based, model-based, and generative approaches. This paper surveys these planning techniques with the goal of clarifying their underlying assumptions, trade-offs, and suitability for different game contexts, and of situating recent LLM-based agents within the broader landscape of game AI planning.

The remainder of this paper is organized as follows. Section~2 provides background on AI planning and discusses the characteristics of games that motivate specialized planning approaches. Section~3 examines hierarchical planning methods, with a focus on HTN-based representations and their use in encoding strategic knowledge. Section~4 reviews Goal-Oriented Action Planning and utility-based decision systems as practical planning frameworks adopted in commercial game development. Section~5 surveys search-based and model-based planning approaches, including Monte Carlo Tree Search, learned world models, and language-based planning agents. Section~6 presents a comparative analysis of these paradigms, highlighting key trade-offs and design considerations. Finally, Section~7 discusses open challenges and future research directions, and Section~8 concludes the paper.


\section{Background: AI Planning in Games}

This section situates planning-based approaches within the broader landscape of game AI. Rather than surveying planning techniques exhaustively, the focus is on clarifying how planning differs from other decision-making paradigms commonly used in games and on identifying the properties of game environments that shape how planning methods are designed and deployed.

\subsection{Planning vs.\ Reactive, Utility-Based, and Learning-Based Game AI}

Game AI has historically been dominated by reactive control architectures, most notably finite state machines and behavior trees. These systems organize behavior procedurally through explicitly defined states, transitions, or control flows. Their appeal lies in their predictability, low computational overhead, and relative ease of debugging, which makes them well suited to production environments. As a result, reactive systems remain widely used in commercial games.

As game complexity increases, however, purely reactive approaches exhibit clear limitations. Authoring and maintaining control logic becomes increasingly difficult as the number of states or behaviors grows, and agents often struggle to generalize beyond situations explicitly anticipated during design. These limitations have motivated interest in decision-making approaches that allow agents to reason more explicitly about goals, trade-offs, and future consequences.

Planning-based approaches occupy a distinct position within this spectrum. By representing goals, actions, and world state explicitly, planning systems enable agents to construct and revise sequences of actions at runtime rather than following fixed control structures. In games, planning is rarely performed as a single offline computation. Instead, planning and execution are typically interleaved, with partial plans generated, adapted, or discarded as the game state evolves. This emphasis on online and incremental planning reflects a key adaptation of classical planning ideas to interactive environments \cite{neufeld2017htn}.

Utility-based decision systems provide an alternative form of deliberation that avoids explicit plan construction. Rather than generating action sequences, Utility AI evaluates available actions using continuous utility or need functions and selects the most desirable option at each decision point. This approach offers a compromise between reactivity and deliberation, supporting smooth adaptation at low computational cost, and has seen widespread adoption in simulation-heavy commercial games \cite{mark2009behavioral}.

Learning-based methods have also become increasingly prominent in game AI, particularly in data-rich settings. Learning can complement planning by providing models, heuristics, or policies that support decision making, and recent work has blurred the boundary between planning and learning by incorporating learned models into planning processes. At the same time, learning-based approaches raise concerns related to predictability, interpretability, and designer control. In practice, planning is therefore commonly combined with reactive, utility-based, and learning-based components rather than used in isolation.

\begin{figure}[t]
    \centering
    \includegraphics[width=\columnwidth]{figures/SECTION2.pdf}
    \caption{Conceptual positioning of decision-making approaches in game AI, illustrating the spectrum from reactive control to planning- and learning-driven behavior.}
    \label{fig:planning-spectrum}
\end{figure}

\subsection{Characteristics of Games Relevant to Planning}

Games differ from classical planning benchmarks in several fundamental ways that strongly influence how planning techniques must be applied. One key distinction concerns timing. Many games operate under strict real-time constraints, requiring agents to act within fixed frame budgets, while others adopt turn-based structures that permit greater deliberation. Planning methods must therefore accommodate varying computational budgets and planning horizons.

Uncertainty is another defining feature of game environments. While some games are largely deterministic, others involve stochastic outcomes, hidden information, or adversarial opponents whose actions cannot be predicted in advance. These factors complicate planning by introducing uncertainty into state transitions and action outcomes, often necessitating frequent replanning, abstraction, or sampling-based decision making.

Games also vary in terms of agency and interaction. Single-agent settings simplify planning by allowing agents to reason in isolation, whereas multi-agent environments introduce additional challenges related to coordination, competition, and interference. Finally, game worlds are typically highly dynamic and only partially observable. World states may change continuously due to physics simulation, non-player characters, and player input, undermining assumptions of static and fully observable environments that underlie many classical planning formulations \cite{kelly2007planning}.

Taken together, these characteristics explain why planning techniques used in games differ substantially from those developed for classical planning benchmarks. Rather than producing complete plans offline, game-oriented planning approaches emphasize incremental reasoning, adaptability, and close integration with execution. These considerations motivate the specialized planning paradigms examined in the following sections.


\section{Hierarchical Planning for Games}

The characteristics of games discussed in the previous section motivate planning approaches that can balance adaptability with designer control. Hierarchical planning has emerged as a particularly influential paradigm in this context, as it enables reasoning at multiple levels of abstraction while constraining agent behavior in ways that remain compatible with game design requirements. This section examines Hierarchical Task Network (HTN) planning as a representative hierarchical approach and situates it alongside related knowledge-driven methods that emphasize structure, reuse, and strategic control.

\begin{figure}[t]
    \centering
    \includegraphics[width=\columnwidth]{figures/SECTION3.pdf}
    \caption{Example Hierarchical Task Network for a guard NPC securing an objective in a game environment. High-level tasks are decomposed into alternative methods and primitive actions, with execution guided by preconditions and evolving world state.}
    \label{fig:htn-network}
\end{figure}

\subsection{Hierarchical Task Networks}

Hierarchical Task Network planning differs from classical goal-based planning by formulating problems in terms of tasks rather than explicit goal states. High-level tasks represent abstract objectives and are recursively decomposed into subtasks through the application of methods, until primitive actions executable in the game world are produced. The resulting hierarchy implicitly encodes control knowledge, guiding the planner toward behavior sequences that are meaningful within the domain.

This task-centered formulation offers several advantages in game settings. By embedding domain knowledge into task decompositions, designers can constrain the space of admissible plans, ensuring that generated behavior aligns with intended gameplay. At the same time, hierarchical abstraction allows agents to reason strategically without committing prematurely to low-level actions. As a result, HTNs are well suited to domains that require long-term planning, coordination, or adherence to narrative structure.

\subsection{Encoding Strategic Knowledge with HTNs}

Hoang et al.\ demonstrated how HTN representations can encode strategic knowledge for game agents in a reusable and modular form \cite{hoang2005hierarchical}. In their approach, high-level strategies are expressed as abstract tasks, while alternative methods specify different ways of realizing these strategies under varying conditions. This structure enables agents to reuse and adapt prior plans rather than generating behavior from scratch.

Hierarchical encoding supports scalability and maintainability by decomposing complex behavior into modular components that can be extended or refined independently. Compared to flat planning representations, this approach reduces combinatorial complexity and promotes consistency in strategic behavior across gameplay scenarios. However, these benefits come at the cost of increased authoring effort. The effectiveness of HTN planning depends heavily on the quality and completeness of the task hierarchy, and overly restrictive or incomplete decompositions can limit behavioral diversity.

\subsection{Case-Based Planning as Knowledge Reuse}

Closely related to hierarchical planning, case-based planning emphasizes reuse of previously observed solutions rather than explicit task decomposition. Agents retrieve and adapt stored cases that represent successful action sequences in similar situations, providing an experience-driven form of deliberation. In games, this approach offers a natural mechanism for encoding tactical and strategic knowledge while reducing online planning effort.

Case-based planning has been applied in both first-person and real-time strategy games, where agents must respond rapidly to recurring situations under real-time constraints \cite{reuss2006casebased,ontanon2007casebased}. From a representational perspective, case-based methods occupy a middle ground between explicit hierarchical planning and reactive control. However, as with HTNs, their effectiveness depends on the quality, coverage, and maintenance of the underlying knowledge base, and adapting cases to novel situations can introduce additional complexity.

\subsection{Hierarchical Planning under Game Constraints}

Subsequent work addressed the challenge of deploying hierarchical planning under real-time game constraints. Kelly et al.\ investigated how HTN planning could be integrated into games where planning and execution must be tightly interleaved \cite{kelly2007planning}. Rather than generating complete plans offline, their approach emphasized incremental planning and execution, allowing agents to revise behavior in response to unexpected state changes.

This shift toward online hierarchical planning improved responsiveness while preserving strategic structure. At the same time, it introduced additional complexity related to plan monitoring, replanning triggers, and computational control. These issues highlight the difficulty of maintaining rich hierarchical structure in environments where timely reaction is essential.

\subsection{Hierarchical Planning in Highly Dynamic Games}

The limits of hierarchical planning in highly dynamic settings were explored by Neufeld et al.\ in the \emph{HTN Fighter} system \cite{neufeld2017htn}. Designed for fast-paced combat scenarios, the system relied on frequent replanning and shallow task decompositions to maintain responsiveness. Rather than prioritizing optimality, the focus shifted toward producing robust behavior under tight time constraints.

This work illustrates a central trade-off in hierarchical planning for games. Deep hierarchies and extensive deliberation support strategic reasoning but are poorly suited to rapidly changing environments. Conversely, reducing hierarchical depth and prioritizing reactive responses improves responsiveness at the expense of long-term optimality. Across the literature, hierarchical and knowledge-driven approaches consistently offer strong designer control and strategic structure, but require careful adaptation to the temporal and dynamic constraints of the game. These limitations motivate the consideration of less structured planning paradigms that emphasize flexibility and scalability, which are examined in the following section.


\section{Goal-Oriented Action Planning in Practice}

Hierarchical and knowledge-driven planning approaches emphasize structure, reuse, and explicit strategic guidance, but their authoring complexity and reliance on detailed domain models can limit their practicality in some game contexts. Goal-Oriented Action Planning (GOAP) emerged as a more lightweight planning framework designed to manage behavioral complexity without deep hierarchies or extensive knowledge bases. This section examines GOAP as a practical alternative to reactive control and situates its adoption within the constraints of commercial game development.

\subsection{From Finite State Machines to Declarative Planning}

The development of GOAP was motivated by the limitations of finite state machines (FSMs) as game AI systems grew in scale. FSM-based architectures encode behavior procedurally through explicit states and transitions, which become increasingly difficult to author and maintain as the number of behaviors increases. As transition logic proliferates, systems become brittle and hard to extend, particularly when new behaviors must interact with existing ones.

GOAP addresses these issues by shifting from procedural control flow to a declarative representation of behavior. Instead of specifying state transitions, designers define actions in terms of preconditions and effects, along with goals that describe desired world-state properties. At runtime, a planner selects and sequences actions based on the current state and the active goal. This decoupling of goals and actions reduces coupling between behaviors and enables agents to respond flexibly to changing circumstances without explicitly enumerating transitions.

Unlike hierarchical or case-based planning approaches, GOAP relies on a flat action representation rather than structured task decompositions or reusable plan fragments. This design choice simplifies authoring and supports rapid adaptation, but limits explicit reasoning about long-term strategy. As a result, GOAP is particularly well suited to tactical decision making in dynamic environments.

\subsection{GOAP in Commercial Games}

A well-known application of GOAP was presented by Orkin in the commercial first-person shooter \emph{F.E.A.R.} \cite{orkin2006three}. In this setting, GOAP replaced large FSM-based systems that had become difficult to scale and maintain within a AAA production pipeline. The planner employed an A*-based search over actions, using action costs as heuristic estimates of desirability.

By decoupling goals from actions, the system enabled non-player characters to exhibit context-sensitive behavior without requiring designers to script all possible scenarios explicitly. Agents selected actions such as seeking cover, flanking enemies, or coordinating with allies based on the current world state and their active goals. Frequent replanning allowed agents to respond to changes in real time, producing behavior that appeared adaptive and coherent from the player’s perspective.

Beyond its technical design, this work demonstrated that planning-based techniques could be integrated into real-time games under strict performance constraints while remaining accessible to designers and compatible with production workflows. As such, GOAP helped establish planning as a viable alternative to large reactive control architectures in commercial game development.

\subsection{Strengths and Limitations of GOAP}

GOAP offers several strengths that have contributed to its adoption in practice. Its declarative representation improves modularity and scalability compared to FSM-based systems, allowing new actions and goals to be introduced with minimal changes to existing behavior logic. Frequent replanning increases robustness in dynamic environments, and the explicit representation of goals and actions supports debugging and tuning by designers.

At the same time, GOAP exhibits clear limitations. As the number of available actions grows, the flat action space can lead to increased planning costs, particularly when replanning is frequent. Moreover, the absence of hierarchical structure or explicit knowledge reuse makes it difficult to encode long-term strategy or high-level narrative constraints. Compared to more structured planning approaches, GOAP provides weaker support for strategic abstraction and designer-authored control.

In practice, these limitations are often mitigated through heuristics, goal prioritization, or domain-specific constraints. Nevertheless, they reflect a recurring trade-off between flexibility and structure that distinguishes GOAP from hierarchical and case-based planning. These considerations motivate the exploration of planning paradigms that further relax symbolic structure in favor of scalability and generality, which are examined in the following section.


\section{Search-Based and Model-Based Planning with State Abstraction}

The planning approaches discussed so far rely on explicit symbolic representations of goals, actions, and domain knowledge. While these representations support interpretability and designer control, they often struggle to scale to environments with large state spaces or complex dynamics. Search-based planning offers an alternative perspective by framing decision making as an online process of exploration and evaluation rather than symbolic reasoning over predefined models. This section reviews search-based and model-based planning approaches for games, with a focus on Monte Carlo Tree Search, abstraction, and recent extensions that incorporate learned and language-based models.

\subsection{Monte Carlo Tree Search for Games}

Monte Carlo Tree Search (MCTS) has become a foundational framework for planning and decision making in games, particularly in domains characterized by uncertainty, adversarial interaction, and large branching factors \cite{chaslot2008mcts}. Rather than constructing explicit plans from symbolic action models, MCTS incrementally builds a search tree through simulated action sequences and statistical evaluation of outcomes, balancing exploration and exploitation.

From a planning perspective, MCTS operates as an online method that evaluates future trajectories instead of producing reusable plans. It requires only a generative model of state transitions, making it attractive in domains where explicit modeling is impractical. At the same time, the absence of explicit goals and symbolic structure distinguishes MCTS from approaches such as HTNs and GOAP, shifting emphasis toward simulation-driven decision making.

\subsection{State Abstraction in Search-Based Planning}

A central challenge for search-based planning in games is the combinatorial growth of state and action spaces, which renders exhaustive search infeasible under real-time constraints. State abstraction addresses this challenge by reducing the effective complexity of the search space, either by grouping similar states or by reasoning at higher levels of granularity.

Abstraction may be domain-dependent, relying on hand-crafted knowledge to focus on strategically relevant features, or domain-independent, using generic feature selection or sampling strategies. While domain-dependent abstraction can be highly effective, it reintroduces authoring effort and limits generality. Domain-independent approaches offer greater flexibility but may sacrifice precision or interpretability. In practice, abstraction enables agents to trade accuracy for responsiveness, which is critical in large strategy games and simulations.

\subsection{Elastic Monte Carlo Tree Search}

Xu et al.\ proposed Elastic Monte Carlo Tree Search as a means of integrating abstraction directly into the search process \cite{xu2022elastic}. Rather than relying on a fixed abstraction scheme, Elastic MCTS dynamically adjusts abstraction granularity based on the available computational budget and properties of the current game state.

This adaptive mechanism allows planners to balance strategic reasoning and real-time responsiveness more effectively than static abstraction schemes. In large strategy games, elastic abstraction enables consideration of long-term consequences without incurring the cost of fine-grained search throughout execution, reducing reliance on explicit domain modeling while preserving strategic capability.

\subsection{Model-Based Planning with Learned Dynamics}

Search-based planning has been further extended through the use of learned models of environment dynamics. Instead of relying on hand-crafted simulators, these approaches learn predictive models from data and use them to guide planning through simulation, blurring the boundary between planning and learning.

Schrittwieser et al.\ demonstrated the effectiveness of this paradigm by combining Monte Carlo Tree Search with learned world models to achieve strong performance across a range of games \cite{schrittwieser2020mastering}. Planning is performed in a learned latent state space, reducing manual modeling effort and improving scalability. However, learned models are less interpretable and shift control away from explicit designer-authored structures, introducing new sources of brittleness.

\subsection{LLM-Based and Generative Planning Agents}

More recently, large language models (LLMs) have been explored as planning components in game-like and simulated environments. Rather than operating over symbolic action models or learned dynamics alone, these systems use natural language as an intermediate representation for goals, plans, and world knowledge, with planning emerging through prompt-driven reasoning or code generation.

Wang et al.\ introduced \emph{Voyager}, an embodied agent that uses an LLM to generate, refine, and reuse plans in a sandbox game environment \cite{wang2023voyager}. Similarly, Park et al.\ proposed generative agents that leverage LLMs to simulate human-like behavior and long-term activity planning in interactive environments \cite{park2023generative}. In both cases, language models function as high-level semantic planners rather than traditional action-level controllers.

LLM-based planning differs fundamentally from symbolic and search-based approaches. By exploiting knowledge encoded in large pretrained models, these systems support expressive and adaptive behavior without predefined action schemas or exhaustive search. At the same time, they introduce challenges related to latency, cost, hallucination, and limited guarantees of correctness, and provide only indirect mechanisms for designer control.

\subsection{Discussion: Symbolic, Search-Based, Model-Based, and Generative Planning}

Symbolic, search-based, model-based, and language-driven planning approaches occupy distinct points in a shared design space. Symbolic planners emphasize structure, interpretability, and designer control, but require substantial authoring effort. Search-based planners emphasize scalability and generality, while model-based planners further reduce manual modeling through learned dynamics. LLM-based agents abstract planning to a semantic level, enabling expressive behavior at the cost of transparency and control.

Together, these paradigms illustrate that contemporary planning in games is increasingly hybrid in nature, combining symbolic structure, search, learning, and language-based reasoning. Understanding their respective trade-offs provides essential context for the comparative analysis presented in the following section.


\section{Comparative Analysis and Synthesis}

The planning approaches surveyed in this paper span a broad spectrum, ranging from symbolic and knowledge-driven methods to search-based, model-based, and language-driven techniques. These paradigms differ fundamentally in how knowledge is represented, how decisions are generated, and how control is shared between designers and autonomous agents. This section compares these approaches along dimensions that are particularly relevant to game AI and synthesizes the resulting trade-offs.

\begin{figure}[t]
    \centering
    \includegraphics[width=\columnwidth]{figures/SECTION6.pdf}
    \caption{Conceptual comparison of planning paradigms in games along a spectrum from explicit, designer-controlled representations to flexible, autonomous decision making.}
    \label{fig:planning-spectrum-comparison}
\end{figure}

\subsection{Representation and Knowledge Encoding}

Planning paradigms differ most clearly in how domain knowledge and behavioral intent are represented. Symbolic approaches rely on explicit representations authored by designers. HTN-based methods encode strategic structure through hierarchical task decompositions, supporting long-term coordination and predictable behavior. GOAP adopts a flatter symbolic representation, defining actions and goals independently to reduce structural complexity while retaining goal-directed reasoning. Case-based planning similarly relies on explicit knowledge, but emphasizes reuse of stored experience rather than predefined hierarchies.

Utility-based decision systems occupy an intermediate position. Rather than constructing explicit plans, Utility AI evaluates actions according to continuous desirability or need functions, avoiding symbolic structure while retaining interpretable decision logic. This approach is widely used in simulation and life-simulation games.

Search-based planning methods avoid explicit symbolic representations altogether, relying instead on simulation, evaluation functions, and abstraction. Model-based planning with learned dynamics further reduces manual modeling by learning predictive representations from data. More recently, LLM-based agents introduce language as an intermediate representation, encoding goals, plans, and world knowledge semantically rather than symbolically. While these approaches substantially reduce authoring effort, they also make behavior harder to interpret and constrain.

\subsection{Reactivity and Adaptability}

Reactivity is a key strength of utility-based, GOAP, and search-based approaches. Utility AI supports continuous adaptation through frequent reevaluation of action utilities, making it well suited to highly dynamic environments. GOAP similarly emphasizes frequent replanning, allowing agents to respond rapidly to changes in world state. Search-based planners achieve adaptability through online simulation and selection, naturally accommodating uncertainty and adversarial dynamics.

HTN-based planners can also adapt at runtime, but typically within the bounds imposed by their hierarchical structure. This constraint improves predictability and alignment with design intent, but may limit responsiveness in rapidly changing environments unless replanning is carefully managed. Model-based planners extend adaptability by enabling search over learned representations, while LLM-based agents support high-level adaptation through semantic reasoning and plan generation, albeit with weaker guarantees of correctness.

\subsection{Computational Considerations}

Real-time performance places strict limits on planning complexity in games. HTN planners manage computational cost by constraining the search space through task decompositions, enabling tractable planning even in complex domains. GOAP and utility-based systems trade structural guidance for simplicity, which can increase computation as the number of actions grows, particularly when replanning or reevaluation is frequent.

Search-based planners face the highest online computational demands due to large state and action spaces, but abstraction and sampling allow them to scale by accepting approximate solutions. Model-based planning shifts much of the computational burden to training learned dynamics models, reducing online modeling costs at the expense of increased system complexity. LLM-based agents introduce additional constraints related to inference latency and cost, which currently limit their use in tight real-time loops.

\subsection{Designer Control and Authoring Effort}

Designer control varies substantially across paradigms. HTNs provide the strongest control, as designers explicitly specify permissible behaviors and strategies through task hierarchies. Case-based planning offers control through curated experience libraries, although behavior depends on coverage and retrieval quality. GOAP and utility-based systems offer a balance between control and flexibility, allowing designers to influence behavior through action definitions, costs, or utility functions without prescribing exact sequences.

Search-based, model-based, and LLM-driven approaches provide the least direct designer control. In these systems, behavior emerges from evaluation, simulation, learned representations, or language-driven reasoning. Authoring effort shifts away from defining behavior toward designing evaluation functions, abstractions, training objectives, or prompts. While this improves scalability and generality, it complicates debugging, predictability, and alignment with narrative or stylistic constraints.

\subsection{Summary of Trade-Offs}

Table~\ref{tab:comparison} summarizes the key characteristics of the planning paradigms discussed in this survey.

\begin{table*}[t]
    \centering
    \small
    \begin{tabular}{lcccccc}
        \hline
        \textbf{Dimension} & \textbf{HTN} & \textbf{GOAP} & \textbf{Utility AI} & \textbf{Search-Based} & \textbf{Model-Based} & \textbf{LLM-Based} \\
        \hline
        Knowledge Encoding & Hierarchical & Symbolic      & Numeric utilities   & Implicit              & Learned              & Language-based     \\
        Reactivity         & Moderate     & High          & High                & High                  & High                 & Moderate--High     \\
        Long-Term Strategy & Strong       & Limited       & Limited             & Emergent              & Emergent             & Emergent           \\
        Designer Control   & High         & Medium        & Medium              & Low                   & Very low             & Very low           \\
        Authoring Effort   & High         & Medium        & Medium              & Low                   & Low (design-time)    & Low (prompting)    \\
        Scalability        & Moderate     & Moderate      & High                & High                  & Very high            & High               \\
        Interpretability   & High         & Medium        & Medium              & Low                   & Low                  & Low                \\
        \hline
    \end{tabular}
    \caption{Comparison of planning paradigms in games across key dimensions.}
    \label{tab:comparison}
\end{table*}

Overall, no single planning paradigm dominates across all criteria. Symbolic and case-based approaches excel in domains that demand strategic consistency and strong designer control. Utility-based and GOAP systems offer practical compromises between structure and flexibility in dynamic settings. Search-based, model-based, and LLM-driven approaches scale to large and complex domains where explicit modeling is impractical, but trade transparency and control for adaptability and generality. These differences underscore the importance of selecting planning techniques based on the specific requirements of the game domain and motivate continued exploration of hybrid and adaptive approaches.


\section{Open Challenges and Research Directions}

Although planning techniques have been applied successfully across many game genres, several open challenges remain. These challenges stem not only from technical limitations, but also from the design, production, and interaction constraints that distinguish games from traditional planning domains. Addressing them is essential for extending the practical impact of planning-based game AI.

A persistent challenge concerns the effort required to author and maintain planning models. Hierarchical and case-based approaches depend on carefully constructed task decompositions or curated experience libraries, while GOAP and utility-based systems rely on well-designed action sets, costs, or utility functions. These representations provide structure and designer control, but they are time-consuming to develop and sensitive to modeling errors. As games evolve during development, maintaining alignment between planning models and game mechanics becomes increasingly burdensome. Reducing authoring cost through improved tooling, higher-level abstractions, or partial automation remains an important research direction.

Closely related is the challenge of integrating planning with learning-based methods. Model-based planning shows how learned dynamics can reduce manual modeling effort and improve scalability, but learned representations are often difficult to interpret and debug. More recently, LLM-based and generative agents have introduced language-level planning based on semantic reasoning. While these systems enable expressive and flexible behavior, they raise additional concerns related to inference latency, computational cost, hallucination, and limited guarantees of correctness. Balancing adaptability with the predictability and control required in game settings remains an open problem.

Evaluation and benchmarking present further difficulties. Unlike classical planning domains, games vary widely in mechanics, objectives, and success criteria. Agent behavior is often judged not only by effectiveness, but also by believability, behavioral diversity, and player experience. These qualitative factors complicate direct comparison of planning approaches and limit the usefulness of purely technical metrics. Developing evaluation methodologies that capture both performance and design-oriented criteria would support more systematic assessment of planning techniques in games.

Scalability under real-time constraints remains a central concern as games grow in complexity. Abstraction, sampling, and incremental planning have enabled decision making in increasingly large state spaces, but guaranteeing timely responses is challenging, particularly in multi-agent settings. For LLM-based agents, these challenges are compounded by inference latency and cost, which currently restrict their use in tight real-time loops. Resource-aware planning and adaptive computation offer promising directions for addressing these constraints.

Finally, the relationship between planning systems and game design raises broader questions about agency and control. Designers must balance autonomous agent behavior with narrative structure, pacing, and aesthetic intent. Planning systems that are too rigid risk producing repetitive behavior, while overly flexible systems may undermine narrative coherence or gameplay balance. This tension is especially pronounced for generative agents, where behavior emerges from pretrained models rather than explicit design constraints. Understanding how planning techniques can better support designer intent, rather than replace scripted control, remains a critical challenge.

Taken together, these issues suggest that the future of planning in games will not be defined by a single dominant paradigm. Instead, progress is likely to emerge from hybrid systems that combine symbolic structure, experience-driven reuse, search-based decision making, learned models, and language-based reasoning. Exploring how these components can be integrated in a principled, controllable, and production-ready manner remains a central research direction for planning-based game AI.


\section{Conclusion}

This paper has surveyed planning-based approaches for game AI, examining a range of paradigms developed to address the unique demands of interactive game environments. Rather than viewing planning as a single, uniform technique, the literature reveals a spectrum of approaches shaped by real-time constraints, dynamic state evolution, uncertainty, and the need to balance autonomous decision making with designer control.

Symbolic and knowledge-driven planning methods, including Hierarchical Task Networks and case-based planning, provide strong structure and interpretability, making them well suited to domains that require long-term strategy, coordination, and explicit design guidance. Goal-Oriented Action Planning offers a more lightweight symbolic alternative, trading strategic structure for flexibility and responsiveness, and has demonstrated its practicality in commercial game development. Utility-based decision systems further illustrate how planner-lite architectures can support robust, scalable behavior without explicit plan construction.

Search-based and model-based planning approaches, particularly those built on Monte Carlo Tree Search, emphasize scalability and generality. By relying on simulation, abstraction, and, in some cases, learned dynamics models, these methods enable decision making in large and uncertain state spaces while reducing reliance on hand-crafted domain representations. More recently, LLM-based and generative agents have introduced a new paradigm in which planning operates at a semantic level, using language as an intermediate representation for goals, plans, and world knowledge. These systems enable expressive and adaptive behavior, but also raise new challenges related to latency, cost, reliability, and designer control.

The comparative analysis highlights that no single planning paradigm is universally optimal across all game scenarios. Instead, the suitability of an approach depends on factors such as computational constraints, the desired level of designer involvement, and the nature of the gameplay experience. In practice, effective game AI systems increasingly combine elements from multiple paradigms, integrating symbolic structure, utility-based decision making, search, learning, and language-driven reasoning within hybrid architectures.

Overall, planning remains a central and evolving component of game AI research. While substantial progress has been made in adapting planning techniques to interactive environments, important challenges related to authoring effort, scalability, evaluation, and the integration of learning and generative models persist. Addressing these challenges will be essential for advancing the role of planning in future games and for narrowing the gap between academic research and practical game development.

\section*{Ethical Statement}
This work was conducted as a literature survey and comparative analysis of existing planning techniques for game AI. No new data involving human subjects or animals were collected, and no ethical concerns arise from the content of this paper. The generative AI tool ChatGPT was used solely for minor language editing and formatting assistance. All sources and contributions have been properly cited to respect intellectual property rights. The author takes full responsibility for the accuracy and integrity of the content presented.

\bibliographystyle{aaai25}
\bibliography{aaai25}

\end{document}
